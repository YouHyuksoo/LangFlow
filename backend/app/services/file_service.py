
import os
import uuid
import aiofiles
import time
import logging
import asyncio
from typing import List, Optional, Dict, Any
from fastapi import UploadFile, HTTPException
from datetime import datetime

from ..models.schemas import FileUploadResponse, FileInfo, FileProcessingOptions
from ..models.vector_models import FileMetadata, FileMetadataService
from ..models.schemas import FileStatus
from ..core.config import settings
from .category_service import CategoryService
from .preprocessing_service import PreprocessingService
from .vector_service import VectorService
from .settings_service import settings_service

# SSE ì´ë²¤íŠ¸ ì „ì†¡ìš©
try:
    from ..api.sse import get_sse_manager
    SSE_AVAILABLE = True
except ImportError:
    SSE_AVAILABLE = False
    print("SSE ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

class FileService:
    """íŒŒì¼ ê´€ë¦¬ ë° ë²¡í„°í™” íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤."""
    def __init__(self):
        self.upload_dir = settings.UPLOAD_DIR
        self.logger = logging.getLogger(__name__)
        self._load_allowed_extensions()
        self.category_service = CategoryService()
        
        # Refactored services
        self.preprocessing_service = PreprocessingService()
        self.vector_service = VectorService()

        # SQLite ê¸°ë°˜ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì„œë¹„ìŠ¤
        self.file_metadata_service = FileMetadataService()
        self._ensure_data_dir()

    # --- ë¶„ë¦¬ëœ ì „ì²˜ë¦¬ ë° ë²¡í„°í™” íŒŒì´í”„ë¼ì¸ ---
    async def start_preprocessing(self, file_id: str, method: str = None):
        """íŒŒì¼ ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        preprocessing_start_time = time.time()
        self.logger.info(f"ğŸ”„ === ì „ì²˜ë¦¬ ì‹œì‘: {file_id} ===")

        try:
            # methodê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            if method is None:
                from .settings_service import settings_service
                system_settings = settings_service.get_section_settings("system")
                method = system_settings.get("preprocessing_method", "basic")
                self.logger.info(f"ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ì „ì²˜ë¦¬ ë°©ì‹: {method}")
            
            file_info = await self.get_file_info(file_id)
            if not file_info or not file_info.file_path or not os.path.exists(file_info.file_path):
                self.logger.error(f"íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_id}")
                await self._update_file_status(file_id, FileStatus.FAILED, error="File not found or path is invalid.")
                return {"success": False, "error": "File not found"}

            if file_info.status != FileStatus.UPLOADED:
                self.logger.warning(f"íŒŒì¼ì´ ì „ì²˜ë¦¬ ê°€ëŠ¥í•œ ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: {file_id}, í˜„ì¬ ìƒíƒœ: {file_info.status}")
                return {"success": False, "error": "File is not in uploadable state"}

            await self._update_file_status(file_id, FileStatus.PREPROCESSING)

            # ì „ì²˜ë¦¬ ì‹¤í–‰
            self.logger.info(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ì‹œì‘ (ë°©ë²•: {method})...")
            text_content = await self.preprocessing_service.process_file(file_info.file_path, method)
            
            # ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
            await self._save_preprocessed_content(file_id, text_content, method)
            
            await self._update_file_status(file_id, FileStatus.PREPROCESSED)
            
            elapsed = time.time() - preprocessing_start_time
            self.logger.info(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content)} (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
            
            return {
                "success": True,
                "text_length": len(text_content),
                "processing_time": elapsed,
                "method": method
            }

        except Exception as e:
            self.logger.error(f"ğŸ’¥ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            await self._update_file_status(file_id, FileStatus.FAILED, error=str(e))
            return {"success": False, "error": str(e)}

    async def start_vectorization(self, file_id: str):
        """ì „ì²˜ë¦¬ëœ íŒŒì¼ì˜ ë²¡í„°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        vectorization_start_time = time.time()
        self.logger.info(f"ğŸš€ === ë²¡í„°í™” ì‹œì‘: {file_id} ===")

        try:
            file_info = await self.get_file_info(file_id)
            if not file_info:
                self.logger.error(f"íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return {"success": False, "error": "File not found"}

            # PREPROCESSING ìƒíƒœë‚˜ FAILED ìƒíƒœì˜ íŒŒì¼ë„ ì¬ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ í—ˆìš©
            if file_info.status not in [FileStatus.UPLOADED, FileStatus.PREPROCESSED, FileStatus.VECTORIZING, FileStatus.PREPROCESSING, FileStatus.FAILED]:
                self.logger.warning(f"íŒŒì¼ì´ ë²¡í„°í™” ê°€ëŠ¥í•œ ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: {file_id}, í˜„ì¬ ìƒíƒœ: {file_info.status}")
                return {"success": False, "error": "File is not ready for vectorization"}
            
            # PREPROCESSING ë˜ëŠ” FAILED ìƒíƒœì¸ ê²½ìš° ê°•ì œ ì¬ì²˜ë¦¬ ì‹œì‘
            if file_info.status in [FileStatus.PREPROCESSING, FileStatus.FAILED]:
                self.logger.info(f"ğŸ”„ ìƒíƒœê°€ {file_info.status}ì¸ íŒŒì¼ì„ ê°•ì œ ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤: {file_id}")
                # ìƒíƒœë¥¼ UPLOADEDë¡œ ì¬ì„¤ì •í•˜ì—¬ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
                await self._update_file_status(file_id, FileStatus.UPLOADED)

            # UPLOADED ìƒíƒœë¼ë©´ ì „ì²˜ë¦¬ë¶€í„° ì‹œì‘
            if file_info.status == FileStatus.UPLOADED:
                self.logger.info(f"UPLOADED ìƒíƒœ íŒŒì¼ ì „ì²˜ë¦¬ ì‹œì‘: {file_id}")
                # ê¸°ë³¸ ì„¤ì •ì—ì„œ ì „ì²˜ë¦¬ ë°©ë²• ê°€ì ¸ì˜¤ê¸° (ì„¤ì •ì— ë”°ë¼ basic, docling, unstructured ì¤‘ ì„ íƒ)
                from .settings_service import settings_service
                system_settings = settings_service.get_section_settings("system")
                preprocessing_method = system_settings.get("preprocessing_method", "basic")
                self.logger.info(f"ì„¤ì •ëœ ì „ì²˜ë¦¬ ë°©ì‹: {preprocessing_method}")
                preprocess_result = await self.start_preprocessing(file_id, preprocessing_method)
                if not preprocess_result.get("success"):
                    self.logger.error(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {file_id}")
                    return {"success": False, "error": "Preprocessing failed"}
                
                # ì „ì²˜ë¦¬ ì™„ë£Œ í›„ íŒŒì¼ ì •ë³´ ë‹¤ì‹œ ë¡œë“œ
                file_info = await self.get_file_info(file_id)

            await self._update_file_status(file_id, FileStatus.VECTORIZING)

            # SSE ì´ë²¤íŠ¸ ì „ì†¡ (ë²¡í„°í™” ì‹œì‘)
            if SSE_AVAILABLE:
                try:
                    sse_manager = get_sse_manager()
                    await sse_manager.broadcast("vectorization_update", {
                        "file_id": file_id,
                        "filename": file_info.filename,
                        "status": "started",
                        "vectorized": False
                    })
                    self.logger.info(f"ğŸ“¡ SSE ë²¡í„°í™” ì‹œì‘ ì´ë²¤íŠ¸ ì „ì†¡: {file_id}")
                except Exception as sse_error:
                    self.logger.warning(f"SSE ì‹œì‘ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {sse_error}")

            # ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë¡œë“œ
            text_content = await self._load_preprocessed_content(file_id)
            if not text_content:
                self.logger.error(f"ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                await self._update_file_status(file_id, FileStatus.FAILED, error="Preprocessed content not found")
                return {"success": False, "error": "Preprocessed content not found"}

            # ë²¡í„°í™” ì‹¤í–‰
            self.logger.info(f"ì²­í‚¹ ë° ì„ë² ë”© ì‹œì‘...")
            vector_metadata = { 
                "filename": file_info.filename, 
                "category_id": file_info.category_id,
                "category_name": file_info.category_name,
                "preprocessing_method": file_info.preprocessing_method
            }
            result = await self.vector_service.chunk_and_embed_text(file_id, text_content, vector_metadata)

            if result.get("success"):
                self.logger.info(f"ğŸ”„ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ - íŒŒì¼ ìƒíƒœë¥¼ COMPLETEDë¡œ ë³€ê²½")
                await self._update_file_status(file_id, FileStatus.COMPLETED, chunks_count=result.get('chunks_count'))
                
                # vectorized í•„ë“œë„ ë³„ë„ë¡œ ì—…ë°ì´íŠ¸
                self.logger.info(f"ğŸ”„ vectorized ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œì‘")
                await self.update_file_vectorization_status(
                    file_id=file_id,
                    vectorized=True,
                    error_message=None,
                    chunk_count=result.get('chunks_count', 0)
                )
                
                elapsed = time.time() - vectorization_start_time
                self.logger.info(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ - ì²­í¬ ìˆ˜: {result.get('chunks_count', 0)}")
                self.logger.info(f"âœ… ë²¡í„°í™” ì„±ê³µ. ì²­í¬ ìˆ˜: {result.get('chunks_count', 0)} (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
                
                # SSE ì´ë²¤íŠ¸ ì „ì†¡ (ë²¡í„°í™” ì™„ë£Œ)
                if SSE_AVAILABLE:
                    try:
                        sse_manager = get_sse_manager()
                        await sse_manager.broadcast("vectorization_update", {
                            "file_id": file_id,
                            "filename": file_info.filename,
                            "status": "completed",
                            "vectorized": True,
                            "chunks_count": result.get('chunks_count', 0),
                            "processing_time": elapsed
                        })
                        self.logger.info(f"ğŸ“¡ SSE ë²¡í„°í™” ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡: {file_id}")
                    except Exception as sse_error:
                        self.logger.warning(f"SSE ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {sse_error}")
                
                return {
                    "success": True,
                    "chunks_count": result.get('chunks_count', 0),
                    "processing_time": elapsed
                }
            else:
                self.logger.error(f"âŒ ë²¡í„°í™” ì‹¤íŒ¨: {result.get('error')}")
                await self._update_file_status(file_id, FileStatus.FAILED, error=result.get('error'))
                
                # SSE ì´ë²¤íŠ¸ ì „ì†¡ (ë²¡í„°í™” ì‹¤íŒ¨)
                if SSE_AVAILABLE:
                    try:
                        sse_manager = get_sse_manager()
                        await sse_manager.broadcast("vectorization_update", {
                            "file_id": file_id,
                            "filename": file_info.filename,
                            "status": "failed",
                            "vectorized": False,
                            "error_message": result.get('error')
                        })
                        self.logger.info(f"ğŸ“¡ SSE ë²¡í„°í™” ì‹¤íŒ¨ ì´ë²¤íŠ¸ ì „ì†¡: {file_id}")
                    except Exception as sse_error:
                        self.logger.warning(f"SSE ì‹¤íŒ¨ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {sse_error}")
                
                return {"success": False, "error": result.get('error')}

        except Exception as e:
            self.logger.error(f"ğŸ’¥ ë²¡í„°í™” ì˜¤ë¥˜: {e}", exc_info=True)
            await self._update_file_status(file_id, FileStatus.FAILED, error=str(e))
            
            # SSE ì´ë²¤íŠ¸ ì „ì†¡ (ë²¡í„°í™” ì˜ˆì™¸ ì˜¤ë¥˜)
            if SSE_AVAILABLE:
                try:
                    file_info = await self.get_file_info(file_id)
                    sse_manager = get_sse_manager()
                    await sse_manager.broadcast("vectorization_update", {
                        "file_id": file_id,
                        "filename": file_info.filename if file_info else "Unknown",
                        "status": "failed",
                        "vectorized": False,
                        "error_message": str(e)
                    })
                    self.logger.info(f"ğŸ“¡ SSE ë²¡í„°í™” ì˜ˆì™¸ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ì „ì†¡: {file_id}")
                except Exception as sse_error:
                    self.logger.warning(f"SSE ì˜ˆì™¸ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: {sse_error}")
            
            return {"success": False, "error": str(e)}

    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ë©”ì„œë“œ (deprecated)
    async def start_vectorization_pipeline(self, file_id: str):
        """ì „ì²´ ë²¡í„°í™” íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤. (deprecated - ì „ì²˜ë¦¬ì™€ ë²¡í„°í™”ê°€ ë¶„ë¦¬ë¨)"""
        self.logger.warning(f"start_vectorization_pipelineì€ deprecated ë©ë‹ˆë‹¤. start_preprocessingê³¼ start_vectorizationì„ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # ìë™ìœ¼ë¡œ ì „ì²˜ë¦¬ ë¨¼ì € ì‹¤í–‰
        preprocess_result = await self.start_preprocessing(file_id)
        if not preprocess_result.get("success"):
            return preprocess_result
            
        # ì „ì²˜ë¦¬ ì„±ê³µ ì‹œ ë²¡í„°í™” ì‹¤í–‰
        return await self.start_vectorization(file_id)

    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ preprocess_file ë©”ì„œë“œ
    async def preprocess_file(self, file_id: str, method: str = "basic"):
        """íŒŒì¼ ì „ì²˜ë¦¬ - start_preprocessingì˜ ë³„ì¹­ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        return await self.start_preprocessing(file_id, method)

    async def _update_file_status(self, file_id: str, status: FileStatus, error: str = None, chunks_count: int = None):
        """íŒŒì¼ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        # ê¸°ì¡´ íŒŒì¼ ì •ë³´ ì¡°íšŒ
        file_metadata = self.file_metadata_service.get_file(file_id)
        if not file_metadata:
            self.logger.error(f"íŒŒì¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
            return
        
        old_status = file_metadata.status
        self.logger.info(f"ğŸ“ íŒŒì¼ ìƒíƒœ ë³€ê²½: {old_status} â†’ {status}")
        
        # ì—…ë°ì´íŠ¸í•  í•„ë“œë“¤
        update_fields = {}
        
        if chunks_count is not None:
            old_chunk_count = file_metadata.chunk_count
            update_fields['chunk_count'] = chunks_count
            self.logger.info(f"ğŸ“Š ì²­í¬ ìˆ˜ ì—…ë°ì´íŠ¸: {old_chunk_count} â†’ {chunks_count}ê°œ")
        
        if error:
            update_fields['error_message'] = error
            self.logger.error(f"âŒ ì‹¤íŒ¨ ìƒíƒœë¡œ ë³€ê²½, ì—ëŸ¬ ë©”ì‹œì§€: {error}")
        elif status == FileStatus.COMPLETED:
            update_fields['error_message'] = None
            self.logger.info(f"ğŸ”„ ì—ëŸ¬ ë©”ì‹œì§€ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # SQLite ìƒíƒœ ì—…ë°ì´íŠ¸
        success = self.file_metadata_service.update_status(
            file_id=file_id,
            status=status,
            **update_fields
        )
        
        if success:
            self.logger.info(f"âœ… SQLite ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # ì—…ë°ì´íŠ¸ í›„ í™•ì¸
            updated_file = self.file_metadata_service.get_file(file_id)
            if updated_file and status == FileStatus.COMPLETED:
                self.logger.info(f"ğŸ” ì—…ë°ì´íŠ¸ í›„ vectorized ê°’: {updated_file.vectorized}")
        else:
            self.logger.error(f"âŒ SQLite ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {file_id}")

    async def _save_preprocessed_content(self, file_id: str, text_content: str, method: str):
        """ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        preprocessed_dir = os.path.join(settings.DATA_DIR, "preprocessed")
        os.makedirs(preprocessed_dir, exist_ok=True)
        
        preprocessed_file = os.path.join(preprocessed_dir, f"{file_id}.txt")
        async with aiofiles.open(preprocessed_file, 'w', encoding='utf-8') as f:
            await f.write(text_content)
            
        # SQLiteì— ì „ì²˜ë¦¬ ë°©ë²• ì €ì¥
        self.file_metadata_service.update_file(
            file_id=file_id,
            preprocessing_method=method
        )

    async def _load_preprocessed_content(self, file_id: str) -> str:
        """ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        preprocessed_file = os.path.join(settings.DATA_DIR, "preprocessed", f"{file_id}.txt")
        if os.path.exists(preprocessed_file):
            async with aiofiles.open(preprocessed_file, 'r', encoding='utf-8') as f:
                return await f.read()
        return ""

    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ deprecated ë©”ì„œë“œ
    async def _update_vectorization_status(self, file_id: str, status: str, error: str = None, chunks_count: int = None):
        """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ deprecated ë©”ì„œë“œ"""
        self.logger.warning("_update_vectorization_statusëŠ” deprecatedë˜ì—ˆìŠµë‹ˆë‹¤. _update_file_statusë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # ê¸°ì¡´ ìƒíƒœë¥¼ ìƒˆë¡œìš´ FileStatusë¡œ ë§¤í•‘
        status_mapping = {
            "processing": FileStatus.PREPROCESSING,
            "completed": FileStatus.COMPLETED,
            "failed": FileStatus.FAILED
        }
        new_status = status_mapping.get(status, FileStatus.FAILED)
        await self._update_file_status(file_id, new_status, error, chunks_count)

    async def update_file_vectorization_status(self, file_id: str, vectorized: bool, error_message: str = None, chunk_count: int = None):
        """íŒŒì¼ì˜ ë²¡í„°í™” ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤ (APIì—ì„œ í˜¸ì¶œìš©)"""
        try:
            # ì—…ë°ì´íŠ¸í•  í•„ë“œë“¤
            update_fields = {
                'vectorized': vectorized
            }
            
            if vectorized:
                update_fields['error_message'] = None
                if chunk_count is not None:
                    update_fields['chunk_count'] = chunk_count
                
                # ìƒíƒœë¥¼ COMPLETEDë¡œ ì—…ë°ì´íŠ¸
                success = self.file_metadata_service.update_status(
                    file_id=file_id,
                    status=FileStatus.COMPLETED,
                    **update_fields
                )
                
                if success:
                    self.logger.info(f"íŒŒì¼ {file_id} ë²¡í„°í™” ìƒíƒœë¥¼ ì„±ê³µìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ì²­í¬: {chunk_count}ê°œ)")
                    return True
            else:
                update_fields['error_message'] = error_message
                status = FileStatus.UPLOADED if not error_message else FileStatus.FAILED
                
                success = self.file_metadata_service.update_status(
                    file_id=file_id,
                    status=status,
                    **update_fields
                )
                
                if success:
                    self.logger.info(f"íŒŒì¼ {file_id} ë²¡í„°í™” ìƒíƒœë¥¼ ì¬ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸")
                    return True
            
            self.logger.error(f"íŒŒì¼ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {file_id}")
            return False
                
        except Exception as e:
            self.logger.error(f"ë²¡í„°í™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {file_id}, ì˜¤ë¥˜: {str(e)}")
            return False

    # --- File Management Methods (Preserved) ---
    def _load_allowed_extensions(self):
        try:
            from .settings_service import settings_service
            system_settings = settings_service.get_section_settings("system")
            allowed_file_types = system_settings.get("allowedFileTypes", ["pdf"])
            self.allowed_extensions = {f".{ext}" if not ext.startswith('.') else ext for ext in allowed_file_types}
        except Exception as e:
            self.logger.warning(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í™•ì¥ì ì‚¬ìš©: {str(e)}")
            self.allowed_extensions = {".pdf", ".docx", ".pptx", ".xlsx", ".txt"}
    
    # FileInfo ì†ì„± í•˜ìœ„ í˜¸í™˜ì„± (schemaì—ì„œ vectorized ì†ì„± ìš”êµ¬)
    def _convert_to_file_info(self, file_metadata: FileMetadata) -> FileInfo:
        """FileMetadataë¥¼ FileInfoë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ"""
        return FileInfo(
            file_id=file_metadata.file_id,
            filename=file_metadata.filename,
            saved_filename=file_metadata.saved_filename,
            file_path=file_metadata.file_path,
            file_size=file_metadata.file_size,
            file_hash=file_metadata.file_hash,
            category_id=file_metadata.category_id,
            category_name=file_metadata.category_name,
            status=file_metadata.status,
            upload_time=file_metadata.upload_time,
            preprocessing_started_at=file_metadata.preprocessing_started_at,
            preprocessing_completed_at=file_metadata.preprocessing_completed_at,
            vectorization_started_at=file_metadata.vectorization_started_at,
            vectorization_completed_at=file_metadata.vectorization_completed_at,
            error_message=file_metadata.error_message,
            chunk_count=file_metadata.chunk_count,
            preprocessing_method=file_metadata.preprocessing_method,
            vectorized=file_metadata.vectorized,  # ì¶”ê°€ëœ í•„ë“œ
            # PDF ë³€í™˜ ì •ë³´ í•„ë“œ ì¶”ê°€
            is_converted_to_pdf=file_metadata.is_converted_to_pdf,
            original_extension=file_metadata.original_extension,
            conversion_method=file_metadata.conversion_method
        )

    def _ensure_data_dir(self):
        os.makedirs(settings.DATA_DIR, exist_ok=True)

    async def upload_file(self, file: UploadFile, category_id: Optional[str] = None, allow_global_duplicates: bool = False, force_replace: bool = False, convert_to_pdf: bool = False) -> FileUploadResponse:
        try:
            file_extension = os.path.splitext(file.filename)[1].lower()
            if file_extension not in self.allowed_extensions:
                raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(self.allowed_extensions)}")
            
            from .settings_service import settings_service
            system_settings = settings_service.get_section_settings("system")
            max_file_size_mb = system_settings.get("maxFileSize", 10)
            max_file_size_bytes = max_file_size_mb * 1024 * 1024
            
            if file.size and file.size > max_file_size_bytes:
                raise HTTPException(status_code=400, detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ í¬ê¸°: {max_file_size_mb}MB")
            
            content = await file.read()
            file_size = len(content)
            
            import hashlib
            file_hash = hashlib.md5(content).hexdigest()
            
            # SQLiteì—ì„œ ì¤‘ë³µ íŒŒì¼ ê²€ì‚¬
            existing_file = self.file_metadata_service.get_file_by_hash(file_hash)
            if existing_file and (allow_global_duplicates or existing_file.category_id == category_id):
                if force_replace:
                    await self.delete_file(existing_file.file_id)
                else:
                    raise HTTPException(
                        status_code=409,
                        detail={"error": "duplicate_file", "message": "ë™ì¼í•œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."}
                    )
            
            file_id = str(uuid.uuid4())
            saved_filename = f"{file_id}{file_extension}"
            file_path = os.path.join(self.upload_dir, saved_filename)
            
            category_name = None
            if category_id:
                category = await self.category_service.get_category(category_id)
                if not category:
                    raise HTTPException(status_code=400, detail="ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤.")
                category_name = category.name
            
            async with aiofiles.open(file_path, 'wb') as f:
                await f.write(content)
            
            # PDF ë³€í™˜ ì²˜ë¦¬ ë° ë³€í™˜ ì •ë³´ ì €ì¥
            original_extension = None
            is_converted = False
            conversion_method = None
            
            if convert_to_pdf and file_extension.lower() != '.pdf':
                self.logger.info(f"PDF ë³€í™˜ ì‹œì‘: {file.filename} -> PDF")
                original_extension = file_extension  # ì›ë³¸ í™•ì¥ì ì €ì¥
                try:
                    pdf_path = await self._convert_to_pdf(file_path, file_id)
                    if pdf_path and os.path.exists(pdf_path):
                        # ì›ë³¸ íŒŒì¼ ì‚­ì œí•˜ê³  PDFë¡œ êµì²´
                        os.remove(file_path)
                        file_path = pdf_path
                        saved_filename = f"{file_id}.pdf"
                        file_extension = '.pdf'
                        # ë³€í™˜ëœ PDF íŒŒì¼ í¬ê¸° ì¬ê³„ì‚°
                        file_size = os.path.getsize(file_path)
                        # ë³€í™˜ ì„±ê³µ ì •ë³´ ì €ì¥
                        is_converted = True
                        conversion_method = "python_lib"
                        self.logger.info(f"PDF ë³€í™˜ ì™„ë£Œ: {saved_filename}")
                    else:
                        self.logger.error(f"PDF ë³€í™˜ ì‹¤íŒ¨: {file.filename}")
                        raise HTTPException(status_code=500, detail="PDF ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                except Exception as convert_error:
                    self.logger.error(f"PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {convert_error}")
                    # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ íŒŒì¼ ìœ ì§€í•˜ê³  ê²½ê³ ë§Œ ë¡œê·¸
                    self.logger.warning(f"PDF ë³€í™˜ ì‹¤íŒ¨ë¡œ ì›ë³¸ íŒŒì¼ ìœ ì§€: {file.filename}")
                    # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë³€í™˜ ì •ë³´ ì´ˆê¸°í™”
                    original_extension = None
                    is_converted = False
                    conversion_method = None
            
            # ê¸°ë³¸ ì „ì²˜ë¦¬ ë°©ë²•ì„ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            system_settings = settings_service.get_section_settings("system")
            default_preprocessing_method = system_settings.get("preprocessing_method", "basic")
            
            # SQLiteì— íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            file_metadata = FileMetadata(
                file_id=file_id,
                filename=file.filename,
                saved_filename=saved_filename,
                file_path=file_path,
                file_size=file_size,
                file_hash=file_hash,
                category_id=category_id,
                category_name=category_name,
                status=FileStatus.UPLOADED,
                upload_time=datetime.now(),
                preprocessing_method=default_preprocessing_method,  # ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ê¸°ë³¸ê°’
                # PDF ë³€í™˜ ì •ë³´ ì €ì¥
                is_converted_to_pdf=is_converted,
                original_extension=original_extension,
                conversion_method=conversion_method
            )
            
            success = self.file_metadata_service.create_file(file_metadata)
            if not success:
                # íŒŒì¼ ì‚­ì œ í›„ ì˜¤ë¥˜ ë°œìƒ
                if os.path.exists(file_path):
                    os.remove(file_path)
                raise HTTPException(status_code=500, detail="íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            return FileUploadResponse(
                file_id=file_id,
                filename=file.filename,
                status=FileStatus.UPLOADED,
                file_size=file_size,
                category_id=category_id,
                category_name=category_name,
                message="íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ëŠ” ë³„ë„ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤."
            )
            
        except HTTPException:
            raise
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def list_files(self, category_id: Optional[str] = None) -> List[FileInfo]:
        file_metadatas = self.file_metadata_service.list_files(
            category_id=category_id,
            include_deleted=False
        )
        
        files = []
        for file_metadata in file_metadatas:
            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if os.path.exists(file_metadata.file_path):
                files.append(self._convert_to_file_info(file_metadata))
        
        return files

    async def get_file_info(self, file_id: str) -> Optional[FileInfo]:
        file_metadata = self.file_metadata_service.get_file(file_id)
        if not file_metadata:
            return None
        
        return self._convert_to_file_info(file_metadata)
    
    async def get_file_content(self, file_id: str) -> Dict[str, Any]:
        """íŒŒì¼ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜ (ì²­í‚¹ìš©)"""
        try:
            # íŒŒì¼ ì •ë³´ ì¡°íšŒ
            file_metadata = self.file_metadata_service.get_file(file_id)
            if not file_metadata:
                return {"success": False, "error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            # ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            preprocessed_path = os.path.join(settings.DATA_DIR, "preprocessed", f"{file_id}.txt")
            
            # ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ë‹¹ ë‚´ìš© ì‚¬ìš©
            if os.path.exists(preprocessed_path):
                try:
                    with open(preprocessed_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return {"success": True, "content": content}
                except Exception as e:
                    self.logger.error(f"ì „ì²˜ë¦¬ëœ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_id}: {e}")
            
            # ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ íŒŒì¼ì—ì„œ ì¶”ì¶œ
            original_path = file_metadata.file_path
            if not os.path.exists(original_path):
                return {"success": False, "error": "ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
            
            # ì‹¤ì œ íŒŒì¼ ê²½ë¡œì˜ í™•ì¥ìë¡œ ì²˜ë¦¬ ë°©ì‹ ê²°ì • (ë³€í™˜ëœ íŒŒì¼ ì§€ì›)
            file_path_lower = original_path.lower()
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ ì½ê¸°
            if file_path_lower.endswith(('.txt', '.md', '.html', '.json', '.xml', '.csv')):
                try:
                    with open(original_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return {"success": True, "content": content}
                except UnicodeDecodeError:
                    try:
                        with open(original_path, 'r', encoding='cp949') as f:
                            content = f.read()
                        return {"success": True, "content": content}
                    except Exception as e:
                        return {"success": False, "error": f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}
            
            # PPTX íŒŒì¼ì¸ ê²½ìš° - í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹ ë¥¸ì²­í‚¹ìš©)
            elif file_path_lower.endswith('.pptx'):
                try:
                    from pptx import Presentation
                    
                    prs = Presentation(original_path)
                    text_content = ""
                    
                    for i, slide in enumerate(prs.slides, 1):
                        slide_text = f"\n=== ìŠ¬ë¼ì´ë“œ {i} ===\n"
                        
                        # ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text.strip():
                                slide_text += shape.text + "\n"
                        
                        text_content += slide_text
                    
                    return {"success": True, "content": text_content.strip()}
                    
                except ImportError:
                    return {"success": False, "error": "PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ python-pptx íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
                except Exception as e:
                    self.logger.error(f"PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ {file_id}: {e}")
                    return {"success": False, "error": f"PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
            
            # DOCX íŒŒì¼ì¸ ê²½ìš° - í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹ ë¥¸ì²­í‚¹ìš©)
            elif file_path_lower.endswith('.docx'):
                try:
                    from docx import Document
                    
                    doc = Document(original_path)
                    text_content = ""
                    
                    for paragraph in doc.paragraphs:
                        if paragraph.text.strip():
                            text_content += paragraph.text + "\n"
                    
                    return {"success": True, "content": text_content.strip()}
                    
                except ImportError:
                    return {"success": False, "error": "DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ python-docx íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
                except Exception as e:
                    self.logger.error(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ {file_id}: {e}")
                    return {"success": False, "error": f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
            
            # PDF íŒŒì¼ì¸ ê²½ìš° - í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹ ë¥¸ì²­í‚¹ìš©)
            elif file_path_lower.endswith('.pdf'):
                try:
                    import fitz  # PyMuPDF
                    
                    doc = fitz.open(original_path)
                    text_content = ""
                    
                    for page_num in range(len(doc)):
                        page = doc[page_num]
                        page_text = page.get_text()
                        if page_text.strip():
                            text_content += f"\n=== í˜ì´ì§€ {page_num + 1} ===\n"
                            text_content += page_text + "\n"
                    
                    doc.close()
                    return {"success": True, "content": text_content.strip()}
                    
                except ImportError:
                    return {"success": False, "error": "PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ PyMuPDF íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
                except Exception as e:
                    self.logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ {file_id}: {e}")
                    return {"success": False, "error": f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
            
            # ê¸°íƒ€ íŒŒì¼ì€ ì „ì²˜ë¦¬ê°€ í•„ìš”
            else:
                return {"success": False, "error": "íŒŒì¼ì´ ì•„ì§ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”."}
            
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ {file_id}: {e}")
            return {"success": False, "error": f"íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

    async def delete_file(self, file_id: str) -> bool:
        file_metadata = self.file_metadata_service.get_file(file_id)
        if not file_metadata:
            return False
        
        try:
            # ë¬¼ë¦¬ íŒŒì¼ ì‚­ì œ
            if os.path.exists(file_metadata.file_path):
                os.remove(file_metadata.file_path)
            
            # ë²¡í„° ë°ì´í„° ì‚­ì œ
            await self.vector_service.delete_document_vectors(file_id)
            
            # SQLiteì—ì„œ ì†Œí”„íŠ¸ ì‚­ì œ (statusë¥¼ deletedë¡œ ë³€ê²½)
            success = self.file_metadata_service.delete_file(file_id, soft_delete=True)
            return success
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}", exc_info=True)
            return False
    
    async def get_file_path(self, file_id: str) -> Optional[str]:
        """íŒŒì¼ ê²½ë¡œ ì¡°íšŒ"""
        file_metadata = self.file_metadata_service.get_file(file_id)
        if file_metadata and os.path.exists(file_metadata.file_path):
            return file_metadata.file_path
        return None
    
    
    
    async def retry_vectorization(self, file_id: str) -> bool:
        """ë²¡í„°í™” ì¬ì‹œë„"""
        try:
            file_metadata = self.file_metadata_service.get_file(file_id)
            if not file_metadata:
                return False
            
            # ìƒíƒœë¥¼ UPLOADEDë¡œ ì¬ì„¤ì •í•˜ê³  ë²¡í„°í™” ì¬ì‹œë„
            self.file_metadata_service.update_status(
                file_id=file_id,
                status=FileStatus.UPLOADED,
                vectorized=False,
                error_message=None
            )
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë²¡í„°í™” ì‹œì‘
            import asyncio
            asyncio.create_task(self.start_vectorization(file_id))
            
            return True
            
        except Exception as e:
            self.logger.error(f"ë²¡í„°í™” ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
            return False
    
    async def set_search_flow(self, flow_id: str) -> bool:
        """ê²€ìƒ‰ Flow ì„¤ì • (í•˜ìœ„ í˜¸í™˜ì„±)"""
        self.logger.warning("set_search_flowëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    async def delete_flow(self, flow_id: str) -> bool:
        """Flow ì‚­ì œ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        self.logger.warning("delete_flowëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    async def cleanup_orphaned_metadata(self) -> int:
        """ê³ ì•„ ë©”íƒ€ë°ì´í„° ì •ë¦¬"""
        try:
            files = self.file_metadata_service.list_files(include_deleted=False)
            orphaned_count = 0
            
            for file_metadata in files:
                # ì‹¤ì œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ìŒ
                if not os.path.exists(file_metadata.file_path):
                    success = self.file_metadata_service.delete_file(
                        file_id=file_metadata.file_id,
                        soft_delete=True
                    )
                    if success:
                        orphaned_count += 1
                        self.logger.info(f"ê³ ì•„ ë©”íƒ€ë°ì´í„° ì‚­ì œ: {file_metadata.file_id}")
            
            return orphaned_count
            
        except Exception as e:
            self.logger.error(f"ê³ ì•„ ë©”íƒ€ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    async def sync_vectorization_status(self) -> Dict[str, Any]:
        """ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™”"""
        try:
            files = self.file_metadata_service.list_files(include_deleted=False)
            corrected_count = 0
            
            for file_metadata in files:
                # ë²¡í„° ì„œë¹„ìŠ¤ì—ì„œ ì‹¤ì œ ë²¡í„° ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                try:
                    has_vectors = await self.vector_service.has_document_vectors(file_metadata.file_id)
                    
                    # ë©”íƒ€ë°ì´í„°ì™€ ì‹¤ì œ ìƒíƒœê°€ ë‹¤ë¥¸ ê²½ìš° ìˆ˜ì •
                    if file_metadata.vectorized != has_vectors:
                        status = FileStatus.COMPLETED if has_vectors else FileStatus.UPLOADED
                        self.file_metadata_service.update_status(
                            file_id=file_metadata.file_id,
                            status=status,
                            vectorized=has_vectors
                        )
                        corrected_count += 1
                        self.logger.info(f"ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™”: {file_metadata.file_id} -> {has_vectors}")
                        
                except Exception as e:
                    self.logger.warning(f"ë²¡í„° ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ {file_metadata.file_id}: {e}")
            
            return {
                "status_corrected": corrected_count,
                "message": f"{corrected_count}ê°œ íŒŒì¼ì˜ ìƒíƒœë¥¼ ë™ê¸°í™”í–ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            self.logger.error(f"ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return {"status_corrected": 0, "error": str(e)}
    
    async def _register_korean_font(self) -> str:
        """í•œê¸€ í°íŠ¸ë¥¼ ë“±ë¡í•˜ê³  í°íŠ¸ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            
            # Windows ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œì—ì„œ í•œê¸€ í°íŠ¸ ì°¾ê¸°
            font_paths = [
                "C:/Windows/Fonts/malgun.ttf",  # ë§‘ì€ê³ ë”•
                "C:/Windows/Fonts/batang.ttf",   # ë°”íƒ•
                "C:/Windows/Fonts/gulim.ttf",    # êµ´ë¦¼
            ]
            
            for font_path in font_paths:
                if os.path.exists(font_path):
                    font_name = os.path.basename(font_path).split('.')[0]
                    try:
                        pdfmetrics.registerFont(TTFont(font_name, font_path))
                        self.logger.info(f"í•œê¸€ í°íŠ¸ ë“±ë¡ ì„±ê³µ: {font_name}")
                        return font_name
                    except Exception as font_error:
                        self.logger.warning(f"í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨ {font_name}: {font_error}")
                        continue
            
            self.logger.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return "Helvetica"
            
        except Exception as e:
            self.logger.error(f"í°íŠ¸ ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return "Helvetica"
    
    async def _convert_to_pdf(self, file_path: str, file_id: str) -> Optional[str]:
        """íŒŒì¼ì„ PDFë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            from reportlab.pdfgen import canvas
            from reportlab.lib.pagesizes import letter
            import openpyxl
            from docx import Document
            
            # ë³€í™˜ëœ PDF íŒŒì¼ ê²½ë¡œ
            pdf_path = os.path.join(self.upload_dir, f"{file_id}.pdf")
            file_extension = os.path.splitext(file_path)[1].lower()
            
            self.logger.info(f"Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë³€í™˜ ì‹œì‘: {file_path} ({file_extension})")
            
            # íŒŒì¼ í˜•ì‹ë³„ ë³€í™˜ ë¡œì§
            if file_extension == '.xlsx' or file_extension == '.xls':
                # Excel íŒŒì¼ ë³€í™˜
                return await self._convert_excel_to_pdf(file_path, pdf_path)
            elif file_extension == '.docx' or file_extension == '.doc':
                # Word íŒŒì¼ ë³€í™˜
                return await self._convert_word_to_pdf(file_path, pdf_path)
            elif file_extension == '.txt':
                # í…ìŠ¤íŠ¸ íŒŒì¼ ë³€í™˜
                return await self._convert_text_to_pdf(file_path, pdf_path)
            else:
                self.logger.warning(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë³€í™˜ í˜•ì‹: {file_extension}")
                return None
                
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.info("pip install reportlab openpyxl python-docx ëª…ë ¹ìœ¼ë¡œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            return None
        except Exception as e:
            self.logger.error(f"PDF ë³€í™˜ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return None
    
    async def _convert_excel_to_pdf(self, excel_path: str, pdf_path: str) -> Optional[str]:
        """Excel íŒŒì¼ì„ PDFë¡œ ë³€í™˜"""
        try:
            import openpyxl
            from reportlab.pdfgen import canvas
            from reportlab.lib.pagesizes import letter
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            
            # í•œê¸€ í°íŠ¸ ë“±ë¡
            korean_font = await self._register_korean_font()
            
            # Excel íŒŒì¼ ì½ê¸° (data_only=Trueë¡œ ìˆ˜ì‹ì˜ ê³„ì‚°ëœ ê°’ ê°€ì ¸ì˜¤ê¸°)
            workbook = openpyxl.load_workbook(excel_path, data_only=True)
            sheet = workbook.active
            
            # PDF ìƒì„±
            c = canvas.Canvas(pdf_path, pagesize=letter)
            width, height = letter
            
            y_position = height - 50
            
            # ì œëª© ì¶”ê°€
            c.setFont(korean_font, 16)
            title = f"Excel íŒŒì¼ ë³€í™˜: {os.path.basename(excel_path)}"
            c.drawString(50, y_position, title)
            y_position -= 40
            
            # ì…€ ë°ì´í„° ì¶œë ¥ (ì…€ ê°ì²´ì— ì§ì ‘ ì ‘ê·¼)
            c.setFont(korean_font, 10)
            for row in sheet.iter_rows():
                if y_position < 50:  # ìƒˆ í˜ì´ì§€
                    c.showPage()
                    c.setFont(korean_font, 10)  # ìƒˆ í˜ì´ì§€ì—ì„œë„ í°íŠ¸ ì¬ì„¤ì •
                    y_position = height - 50
                
                # í•œê¸€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                row_cells = []
                for cell in row:
                    if cell.value is not None:
                        # ê³„ì‚°ëœ ê°’ ìš°ì„  ì‚¬ìš©
                        if hasattr(cell, 'displayed_value') and cell.displayed_value is not None:
                            cell_str = str(cell.displayed_value)
                        elif cell.data_type == 'f' and cell.value:  # ìˆ˜ì‹ ì…€
                            # ìˆ˜ì‹ì˜ ê³„ì‚°ëœ ê²°ê³¼ê°’ ì‹œë„
                            try:
                                # ê³„ì‚°ëœ ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                                if hasattr(cell, '_value') and cell._value is not None:
                                    cell_str = str(cell._value)
                                else:
                                    cell_str = f"[ê³„ì‚°ê°’ ì—†ìŒ: {str(cell.value)[:15]}...]"
                            except:
                                cell_str = f"[ìˆ˜ì‹: {str(cell.value)[:15]}...]"
                        else:
                            cell_str = str(cell.value)
                        
                        # í•œê¸€ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ëŠ” ë” ì§§ê²Œ ìë¥´ê¸°
                        if any('\u4e00' <= char <= '\u9fff' or '\uac00' <= char <= '\ud7af' for char in cell_str):
                            cell_str = cell_str[:30]  # í•œê¸€/í•œì í¬í•¨ ì‹œ ì§§ê²Œ
                        else:
                            cell_str = cell_str[:50]  # ì˜ë¬¸ì€ ì¢€ ë” ê¸¸ê²Œ
                        row_cells.append(cell_str)
                    else:
                        row_cells.append("")
                
                row_text = " | ".join(row_cells)
                try:
                    c.drawString(50, y_position, row_text)
                except Exception as draw_error:
                    # í•œê¸€ ì¶œë ¥ ì‹¤íŒ¨ ì‹œ ASCIIë§Œ ì¶œë ¥
                    ascii_text = ''.join(char if ord(char) < 128 else '?' for char in row_text)
                    c.drawString(50, y_position, ascii_text)
                    
                y_position -= 15
            
            c.save()
            self.logger.info(f"Excel -> PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
            return pdf_path
            
        except Exception as e:
            self.logger.error(f"Excel PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    async def _convert_word_to_pdf(self, word_path: str, pdf_path: str) -> Optional[str]:
        """Word íŒŒì¼ì„ PDFë¡œ ë³€í™˜"""
        try:
            from docx import Document
            from reportlab.pdfgen import canvas
            from reportlab.lib.pagesizes import letter
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            
            # í•œê¸€ í°íŠ¸ ë“±ë¡
            korean_font = await self._register_korean_font()
            
            # Word íŒŒì¼ ì½ê¸°
            doc = Document(word_path)
            
            # PDF ìƒì„±
            c = canvas.Canvas(pdf_path, pagesize=letter)
            width, height = letter
            
            y_position = height - 50
            
            # ì œëª© ì¶”ê°€
            c.setFont(korean_font, 16)
            title = f"Word íŒŒì¼ ë³€í™˜: {os.path.basename(word_path)}"
            c.drawString(50, y_position, title)
            y_position -= 40
            
            # ë¬¸ë‹¨ ì¶œë ¥
            c.setFont(korean_font, 12)
            for paragraph in doc.paragraphs:
                if y_position < 50:  # ìƒˆ í˜ì´ì§€
                    c.showPage()
                    c.setFont(korean_font, 12)
                    y_position = height - 50
                
                # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
                text = paragraph.text
                if text.strip():
                    # í•œê¸€ ê³ ë ¤í•˜ì—¬ ì¤„ ê¸¸ì´ ì¡°ì •
                    line_length = 40 if any('\uac00' <= char <= '\ud7af' for char in text) else 80
                    lines = [text[i:i+line_length] for i in range(0, len(text), line_length)]
                    for line in lines:
                        if y_position < 50:
                            c.showPage()
                            c.setFont(korean_font, 12)
                            y_position = height - 50
                        try:
                            c.drawString(50, y_position, line)
                        except Exception:
                            # í•œê¸€ ì¶œë ¥ ì‹¤íŒ¨ ì‹œ ASCIIë§Œ ì¶œë ¥
                            ascii_line = ''.join(char if ord(char) < 128 else '?' for char in line)
                            c.drawString(50, y_position, ascii_line)
                        y_position -= 15
                    y_position -= 5  # ë¬¸ë‹¨ ê°„ê²©
            
            c.save()
            self.logger.info(f"Word -> PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
            return pdf_path
            
        except Exception as e:
            self.logger.error(f"Word PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    async def _convert_text_to_pdf(self, text_path: str, pdf_path: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ì„ PDFë¡œ ë³€í™˜"""
        try:
            from reportlab.pdfgen import canvas
            from reportlab.lib.pagesizes import letter
            
            # í•œê¸€ í°íŠ¸ ë“±ë¡
            korean_font = await self._register_korean_font()
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
            with open(text_path, 'r', encoding='utf-8') as f:
                text_content = f.read()
            
            # PDF ìƒì„±
            c = canvas.Canvas(pdf_path, pagesize=letter)
            width, height = letter
            
            y_position = height - 50
            
            # ì œëª© ì¶”ê°€
            c.setFont(korean_font, 16)
            title = f"í…ìŠ¤íŠ¸ íŒŒì¼ ë³€í™˜: {os.path.basename(text_path)}"
            c.drawString(50, y_position, title)
            y_position -= 40
            
            # í…ìŠ¤íŠ¸ ì¶œë ¥
            c.setFont(korean_font, 12)
            lines = text_content.split('\n')
            for line in lines:
                if y_position < 50:  # ìƒˆ í˜ì´ì§€
                    c.showPage()
                    c.setFont(korean_font, 12)
                    y_position = height - 50
                
                # í•œê¸€ ê³ ë ¤í•˜ì—¬ ì¤„ ê¸¸ì´ ì¡°ì •
                line_length = 40 if any('\uac00' <= char <= '\ud7af' for char in line) else 80
                
                # ê¸´ ì¤„ì„ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
                if len(line) > line_length:
                    sub_lines = [line[i:i+line_length] for i in range(0, len(line), line_length)]
                    for sub_line in sub_lines:
                        if y_position < 50:
                            c.showPage()
                            c.setFont(korean_font, 12)
                            y_position = height - 50
                        try:
                            c.drawString(50, y_position, sub_line)
                        except Exception:
                            # í•œê¸€ ì¶œë ¥ ì‹¤íŒ¨ ì‹œ ASCIIë§Œ ì¶œë ¥
                            ascii_line = ''.join(char if ord(char) < 128 else '?' for char in sub_line)
                            c.drawString(50, y_position, ascii_line)
                        y_position -= 15
                else:
                    try:
                        c.drawString(50, y_position, line)
                    except Exception:
                        # í•œê¸€ ì¶œë ¥ ì‹¤íŒ¨ ì‹œ ASCIIë§Œ ì¶œë ¥
                        ascii_line = ''.join(char if ord(char) < 128 else '?' for char in line)
                        c.drawString(50, y_position, ascii_line)
                    y_position -= 15
            
            c.save()
            self.logger.info(f"Text -> PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
            return pdf_path
            
        except Exception as e:
            self.logger.error(f"Text PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
