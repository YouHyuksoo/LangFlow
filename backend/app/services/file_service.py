import os
import uuid
import aiofiles
import json
from typing import List, Optional, Dict, Any
from fastapi import UploadFile, HTTPException
from ..models.schemas import FileUploadResponse, FileInfo
from ..core.config import settings
from datetime import datetime
from .category_service import CategoryService
from ..api.settings import load_settings
# LangflowServiceëŠ” ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì²˜ë¦¬ (ìˆœí™˜ import ë°©ì§€)
# VectorServiceëŠ” ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì²˜ë¦¬

class FileService:
    def __init__(self):
        self.upload_dir = settings.UPLOAD_DIR
        self.max_file_size = settings.MAX_FILE_SIZE
        # ë™ì ìœ¼ë¡œ ì„¤ì •ì—ì„œ í—ˆìš© í™•ì¥ì ë¡œë“œ
        from ..api.settings import load_settings
        current_settings = load_settings()
        # ì„¤ì •ì—ì„œ í—ˆìš©ëœ íŒŒì¼ í˜•ì‹ì„ ê°€ì ¸ì™€ì„œ í™•ì¥ìë¡œ ë³€í™˜ (.pdf -> .pdf)
        allowed_file_types = current_settings.get("allowedFileTypes", ["pdf"])
        self.allowed_extensions = {f".{ext}" if not ext.startswith('.') else ext for ext in allowed_file_types}
        self.category_service = CategoryService()
        # ë²¡í„° ì„œë¹„ìŠ¤ëŠ” ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì²˜ë¦¬ - ë²¡í„°í™” ê´€ë ¨ ì‘ì—…ì—ì„œë§Œ ì´ˆê¸°í™”
        self._vector_service = None
        
        # ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.upload_dir, exist_ok=True)
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ íŒŒì¼
        self.files_metadata_file = os.path.join(settings.DATA_DIR, "files_metadata.json")
        self._ensure_data_dir()
        self._load_files_metadata()
    
    @property
    def vector_service(self):
        """ë²¡í„° ì„œë¹„ìŠ¤ë¥¼ ì§€ì—° ë¡œë”©ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤ (ë²¡í„°í™” ì‘ì—…ì—ì„œë§Œ ì´ˆê¸°í™”)."""
        if self._vector_service is None:
            print("VectorService ì§€ì—° ë¡œë”© ì´ˆê¸°í™” ì¤‘...")
            try:
                from .vector_service import VectorService
                self._vector_service = VectorService()
            except Exception as e:
                print(f"VectorService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                # VectorService ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•ŠìŒ
                # ëŒ€ì‹  Noneì„ ë°˜í™˜í•˜ì—¬ ìƒìœ„ì—ì„œ ì²˜ë¦¬
                self._vector_service = None
        return self._vector_service
    
    def _ensure_data_dir(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
        data_dir = settings.DATA_DIR
        os.makedirs(data_dir, exist_ok=True)
    
    def _load_files_metadata(self):
        """íŒŒì¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.files_metadata_file):
            try:
                with open(self.files_metadata_file, 'r', encoding='utf-8') as f:
                    loaded_metadata = json.load(f)
                
                # ë¡œë“œëœ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                if isinstance(loaded_metadata, dict):
                    self.files_metadata = loaded_metadata
                elif isinstance(loaded_metadata, list):
                    print("files_metadataê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì…ë‹ˆë‹¤. ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                    self.files_metadata = {}
                else:
                    print(f"files_metadataì˜ ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…: {type(loaded_metadata)}")
                    self.files_metadata = {}
            except Exception as e:
                print(f"íŒŒì¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                self.files_metadata = {}
        else:
            self.files_metadata = {}
    
    def _save_files_metadata(self):
        """íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            with open(self.files_metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.files_metadata, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            print(f"íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    async def upload_file(self, file: UploadFile, category_id: Optional[str] = None, allow_global_duplicates: bool = False, force_replace: bool = False) -> FileUploadResponse:
        """íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë²¡í„°í™” ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ í™•ì¥ì ê²€ì¦
            file_extension = os.path.splitext(file.filename)[1].lower()
            if file_extension not in self.allowed_extensions:
                raise HTTPException(
                    status_code=400, 
                    detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(self.allowed_extensions)}"
                )
            
            # íŒŒì¼ í¬ê¸° ê²€ì¦ (ë™ì  ì„¤ì • ì‚¬ìš©)
            current_settings = load_settings()
            max_file_size_mb = current_settings.get("maxFileSize", 10)
            max_file_size_bytes = max_file_size_mb * 1024 * 1024
            
            if file.size and file.size > max_file_size_bytes:
                raise HTTPException(
                    status_code=400,
                    detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ í¬ê¸°: {max_file_size_mb}MB"
                )
            
            # ì¤‘ë³µ íŒŒì¼ ê²€ì¶œ
            content = await file.read()
            file_size = len(content)
            
            # íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ê²€ì¶œìš©)
            import hashlib
            file_hash = hashlib.md5(content).hexdigest()
            
            # ì¤‘ë³µ íŒŒì¼ ê²€ì¶œ - ì‚­ì œë˜ì§€ ì•Šì€ íŒŒì¼ë“¤ë§Œ í™•ì¸
            print(f"íŒŒì¼ ì¤‘ë³µ ê²€ì‚¬ ì‹œì‘: {file.filename} (í•´ì‹œ: {file_hash[:8]}...)")
            for existing_file_id, existing_file_data in self.files_metadata.items():
                # ì‚­ì œëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                if existing_file_data.get("status") == "deleted":
                    continue
                
                existing_hash = existing_file_data.get("file_hash")
                existing_filename = existing_file_data.get("filename")
                existing_category = existing_file_data.get("category_id")
                
                print(f"ê¸°ì¡´ íŒŒì¼ í™•ì¸: {existing_filename} (í•´ì‹œ: {existing_hash[:8] if existing_hash else 'None'}...)")
                
                # í•´ì‹œê°€ ê°™ì€ íŒŒì¼ ê²€ì¶œ (ì¹´í…Œê³ ë¦¬ ì¡°ê±´ í™•ì¸)
                if (existing_hash == file_hash and 
                    existing_hash is not None and  # í•´ì‹œê°€ ìˆëŠ” íŒŒì¼ë§Œ ë¹„êµ
                    (allow_global_duplicates or existing_category == category_id)):  # ì „ì—­ í—ˆìš© ë˜ëŠ” ê°™ì€ ì¹´í…Œê³ ë¦¬
                    
                    print(f"ì¤‘ë³µ íŒŒì¼ ë°œê²¬: {existing_filename} (ID: {existing_file_id})")
                    
                    if force_replace:
                        # ê°•ì œ êµì²´ ëª¨ë“œ: ê¸°ì¡´ íŒŒì¼ ì‚­ì œ í›„ ìƒˆ íŒŒì¼ë¡œ êµì²´
                        print(f"ê¸°ì¡´ íŒŒì¼ êµì²´ ëª¨ë“œ: {existing_filename}")
                        await self.delete_file(existing_file_id)
                        # êµì²´ í›„ ìƒˆ íŒŒì¼ ì—…ë¡œë“œë¥¼ ê³„ì† ì§„í–‰í•˜ê¸° ìœ„í•´ continue
                        continue
                    else:
                        # ì¤‘ë³µ íŒŒì¼ ì •ë³´ì™€ í•¨ê»˜ ì‘ë‹µ ìƒì„±
                        raise HTTPException(
                            status_code=409,
                            detail={
                                "error": "duplicate_file",
                                "message": "ë™ì¼í•œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.",
                                "existing_file": {
                                    "file_id": existing_file_id,
                                    "filename": existing_filename,
                                    "category_id": existing_category,
                                    "category_name": existing_file_data.get("category_name", ""),
                                },
                                "new_file": {
                                    "filename": file.filename,
                                    "size": file_size,
                                    "category_id": category_id,
                                }
                            }
                        )
                
                # íŒŒì¼ëª…ê³¼ í¬ê¸°ê°€ ë™ì¼í•˜ì§€ë§Œ í•´ì‹œê°€ ì—†ëŠ” ê¸°ì¡´ íŒŒì¼ì˜ ê²½ìš° (ì´ì „ ë²„ì „ í˜¸í™˜ì„±)
                elif (existing_filename == file.filename and 
                      existing_file_data.get("file_size") == file_size and
                      existing_category == category_id and
                      existing_hash is None):  # ê¸°ì¡´ íŒŒì¼ì— í•´ì‹œê°€ ì—†ëŠ” ê²½ìš°
                    
                    print(f"í•´ì‹œ ì—†ëŠ” ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {existing_filename}")
                    
                    if force_replace:
                        # ê°•ì œ êµì²´ ëª¨ë“œ: ê¸°ì¡´ íŒŒì¼ ì‚­ì œ í›„ ìƒˆ íŒŒì¼ë¡œ êµì²´
                        print(f"ê¸°ì¡´ íŒŒì¼ êµì²´ ëª¨ë“œ (í•´ì‹œ ì—†ìŒ): {existing_filename}")
                        await self.delete_file(existing_file_id)
                        # êµì²´ í›„ ìƒˆ íŒŒì¼ ì—…ë¡œë“œë¥¼ ê³„ì† ì§„í–‰í•˜ê¸° ìœ„í•´ continue
                        continue
                    else:
                        # ê¸°ì¡´ íŒŒì¼ì— í•´ì‹œ ì •ë³´ ì¶”ê°€
                        existing_file_data["file_hash"] = file_hash
                        self._save_files_metadata()
                        
                        # ì¤‘ë³µ íŒŒì¼ ì‘ë‹µ ìƒì„± (í•´ì‹œ ì¶”ê°€ë¨)
                        response = FileUploadResponse(
                            file_id=existing_file_id,
                            filename=file.filename,
                            status=existing_file_data.get("status", "pending_vectorization"),
                            file_size=file_size,
                            category_id=category_id,
                            category_name=existing_file_data.get("category_name"),
                            message=f"ì¤‘ë³µ íŒŒì¼ ê°ì§€: '{existing_filename}'ê³¼ ë™ì¼í•œ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
                        )
                        # ì¤‘ë³µ í”Œë˜ê·¸ ì¶”ê°€ (ë™ì  ì†ì„±)
                        response.__dict__['is_duplicate'] = True
                        response.__dict__['existing_file_id'] = existing_file_id
                        return response
            
            print(f"ì¤‘ë³µ íŒŒì¼ ì—†ìŒ, ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì—…ë¡œë“œ ì§„í–‰: {file.filename}")
            
            # ê³ ìœ  íŒŒì¼ ID ìƒì„±
            file_id = str(uuid.uuid4())
            file_extension = os.path.splitext(file.filename)[1]
            saved_filename = f"{file_id}{file_extension}"
            file_path = os.path.join(self.upload_dir, saved_filename)
            
            # ì¹´í…Œê³ ë¦¬ ê²€ì¦
            category_name = None
            if category_id:
                category = await self.category_service.get_category(category_id)
                if not category:
                    raise HTTPException(status_code=400, detail="ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤.")
                category_name = category.name
            
            # íŒŒì¼ ì €ì¥
            async with aiofiles.open(file_path, 'wb') as f:
                await f.write(content)
            
            # íŒŒì¼ ì •ë³´ ì €ì¥
            file_info = {
                "file_id": file_id,
                "filename": file.filename,
                "saved_filename": saved_filename,
                "file_path": file_path,
                "file_size": file_size,
                "file_hash": file_hash,  # ì¤‘ë³µ ê²€ì¶œìš© í•´ì‹œ ì¶”ê°€
                "category_id": category_id,
                "category_name": category_name,
                "status": "uploaded",  # ë‹¨ìˆœ ì—…ë¡œë“œ ìƒíƒœë¡œ ë³€ê²½
                "upload_time": datetime.now(),
                "vectorized": False
            }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.files_metadata[file_id] = file_info
            self._save_files_metadata()
            
            # ëª¨ë“  ì§€ì› íŒŒì¼ì— ëŒ€í•´ ë™ì¼í•œ ë²¡í„°í™” ì•ˆë‚´ ë©”ì‹œì§€ (PDF, Office íŒŒì¼ ëª¨ë‘ ì§€ì›)
            message = "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë²¡í„°í™”ëŠ” ë³„ë„ ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
            
            return FileUploadResponse(
                file_id=file_id,
                filename=file.filename,
                status="uploaded",  # ìƒíƒœ ë³€ê²½
                file_size=file_size,
                category_id=category_id,
                category_name=category_name,
                message=message
            )
            
        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise
        except Exception as e:
            print(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def _start_vectorization(self, file_id: str):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì¼ ë²¡í„°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        try:
            print(f"=== ë²¡í„°í™” ì‹œì‘: {file_id} ===")
            
            # íŒŒì¼ ì •ë³´ ì¡°íšŒ
            file_info = await self.get_file_info(file_id)
            if not file_info:
                print(f"íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return
            
            print(f"íŒŒì¼ ì •ë³´: {file_info.filename}, ì¹´í…Œê³ ë¦¬: {file_info.category_name}")
            
            # íŒŒì¼ ìƒíƒœë¥¼ ë²¡í„°í™” ëŒ€ê¸° ì¤‘ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            if file_id in self.files_metadata:
                self.files_metadata[file_id]["status"] = "pending_vectorization"
                self._save_files_metadata()
                print(f"ìƒíƒœ ì—…ë°ì´íŠ¸: pending_vectorization")
            
            # ë²¡í„°í™” Flow ID ê²°ì •
            print("ë²¡í„°í™” Flow ID ê²°ì • ì¤‘...")
            vectorization_flow_id = await self._determine_vectorization_flow(file_id)
            
            if not vectorization_flow_id:
                print(f"ì ì ˆí•œ ë²¡í„°í™” Flowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë²¡í„°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {file_id}")
                # ë²¡í„°í™” ëŒ€ê¸° ìƒíƒœë¡œ ìœ ì§€
                if file_id in self.files_metadata:
                    self.files_metadata[file_id]["status"] = "pending_vectorization"
                    self.files_metadata[file_id]["vectorized"] = False
                    self._save_files_metadata()
                return
            
            print(f"ì„ íƒëœ Flow ID: {vectorization_flow_id}")
            
            # ë²¡í„°í™” ì‹œì‘ - ìƒíƒœë¥¼ ë²¡í„°í™” ì¤‘ìœ¼ë¡œ ë³€ê²½
            if file_id in self.files_metadata:
                self.files_metadata[file_id]["status"] = "vectorizing"
                self._save_files_metadata()
                print(f"ìƒíƒœ ì—…ë°ì´íŠ¸: vectorizing")
            
            # LangFlowë¥¼ í†µí•œ ë²¡í„°í™” ì‹¤í–‰
            print("LangFlow ë²¡í„°í™” ì‹¤í–‰ ì‹œì‘...")
            try:
                from .langflow_service import LangflowService
                langflow_service = LangflowService()
                result = await langflow_service.process_file_with_flow(file_id, vectorization_flow_id, file_info)
                print(f"LangFlow ë²¡í„°í™” ê²°ê³¼: {result}")
            except Exception as e:
                print(f"LangflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                result = {"status": "failed", "error": str(e)}
            
            # ë²¡í„°í™” ì™„ë£Œ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸
            if file_id in self.files_metadata:
                if result.get("status") == "completed":
                    self.files_metadata[file_id]["status"] = "vectorized"
                    self.files_metadata[file_id]["vectorized"] = True
                    self.files_metadata[file_id]["vectorized_at"] = datetime.now()
                    self.files_metadata[file_id]["used_flow_id"] = vectorization_flow_id
                    print(f"ë²¡í„°í™” ì™„ë£Œ: {file_id} (Flow: {vectorization_flow_id})")
                else:
                    self.files_metadata[file_id]["status"] = "vectorization_failed"
                    self.files_metadata[file_id]["error"] = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    print(f"ë²¡í„°í™” ì‹¤íŒ¨: {file_id}")
                    print(f"ì˜¤ë¥˜ ë‚´ìš©: {result.get('error')}")
                
                self._save_files_metadata()
                print(f"ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸: {self.files_metadata[file_id]['status']}")
                
        except Exception as e:
            print(f"ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_id}, ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
            if file_id in self.files_metadata:
                self.files_metadata[file_id]["status"] = "vectorization_failed"
                self.files_metadata[file_id]["error"] = str(e)
                self._save_files_metadata()
    
    async def _determine_vectorization_flow(self, file_id: str) -> Optional[str]:
        """ê´€ë¦¬ìê°€ í™œì„±í™”í•œ ë²¡í„°í™” Flowë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        try:
            # 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ë²¡í„°í™” Flow ID í™•ì¸
            default_flow_id = getattr(settings, 'DEFAULT_VECTORIZATION_FLOW_ID', None)
            
            if default_flow_id:
                print(f"í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ë²¡í„°í™” Flow ì‚¬ìš©: {default_flow_id}")
                return default_flow_id
            
            # 2. ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ ë²¡í„°í™” Flow ID í™•ì¸
            config_file = os.path.join(settings.BASE_DIR, "langflow", "config.json")
            if os.path.exists(config_file):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                    config_flow_id = config_data.get("default_vectorization_flow_id")
                    if config_flow_id:
                        print(f"ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ ë²¡í„°í™” Flow ì‚¬ìš©: {config_flow_id}")
                        return config_flow_id
                except Exception as e:
                    print(f"ì„¤ì • íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            
            # 3. LangflowServiceì—ì„œ í™œì„± Flow í™•ì¸
            try:
                from .langflow_service import LangflowService
                langflow_service = LangflowService()
                active_flows = await langflow_service.get_flows()
                vectorization_flows = [flow for flow in active_flows if flow.get("is_active", False)]
                
                if vectorization_flows:
                    # ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ Flow ì„ íƒ
                    latest_flow = max(vectorization_flows, key=lambda x: x.get("updated_at", x.get("created_at", "")))
                    print(f"í™œì„± Flow ì‚¬ìš©: {latest_flow['flow_id']} ({latest_flow['name']})")
                    return latest_flow['flow_id']
            except Exception as e:
                print(f"LangflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            
            print("í™œì„±í™”ëœ ë²¡í„°í™” Flowê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"Flow ê²°ì • ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return getattr(settings, 'DEFAULT_VECTORIZATION_FLOW_ID', None)
    
    async def vectorize_file(self, file_id: str) -> bool:
        """íŒŒì¼ì„ ë²¡í„°í™”í•©ë‹ˆë‹¤. (LangFlowë§Œ ì‚¬ìš©)"""
        try:
            # ë²¡í„°í™” Flow ID ê²°ì •
            vectorization_flow_id = await self._determine_vectorization_flow(file_id)
            
            if not vectorization_flow_id:
                print(f"LangFlow Flow IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {file_id}")
                return False
            
            # LangFlowë¥¼ í†µí•œ ë²¡í„°í™”
            file_info = await self.get_file_info(file_id)
            if not file_info:
                print(f"íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return False
                
            try:
                from .langflow_service import LangflowService
                langflow_service = LangflowService()
                result = await langflow_service.process_file_with_flow(file_id, vectorization_flow_id, file_info)
            except Exception as e:
                print(f"LangflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                return False
            
            if result.get("status") == "completed":
                print(f"LangFlow ë²¡í„°í™” ì™„ë£Œ: {file_id}")
                return True
            else:
                print(f"LangFlow ë²¡í„°í™” ì‹¤íŒ¨: {file_id}")
                return False
                
        except Exception as e:
            print(f"ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    async def get_file_info(self, file_id: str) -> Optional[FileInfo]:
        """íŒŒì¼ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            file_data = self.files_metadata.get(file_id)
            if file_data:
                return FileInfo(**file_data)
            return None
        except Exception as e:
            print(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def list_files(self, category_id: Optional[str] = None) -> List[FileInfo]:
        """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            # ìƒì„¸ ë””ë²„ê·¸ ì¶œë ¥ ì œê±°
            files = []
            orphaned_metadata = []  # ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not hasattr(self, 'files_metadata') or self.files_metadata is None:
                # ì¡°ìš©íˆ ì¬ë¡œë“œ
                self._load_files_metadata()
            
            if not self.files_metadata:
                # ë©”íƒ€ë°ì´í„° ì—†ìŒ
                return []
            
            # ê³¼ë„í•œ ë””ë²„ê·¸ ì œê±°
            
            # íŒŒì¼ ëª©ë¡ ì¡°íšŒ - LangflowService ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            for file_id, file_data in self.files_metadata.items():
                try:
                    # ìƒì„¸ ì²˜ë¦¬ ë¡œê·¸ ì œê±°
                    
                    # file_data íƒ€ì… ê²€ì¦
                    if not isinstance(file_data, dict):
                        # íƒ€ì… ë¹„ì •ìƒì€ ìŠ¤í‚µ
                        continue
                    
                    # ì‚­ì œëœ íŒŒì¼ ì œì™¸
                    if file_data.get("status") == "deleted":
                        # ì‚­ì œëœ íŒŒì¼ ìŠ¤í‚µ
                        continue
                        
                    # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                    if category_id is not None and file_data.get("category_id") != category_id:
                        # ì¹´í…Œê³ ë¦¬ í•„í„° ìŠ¤í‚µ
                        continue
                    
                    # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    file_path = file_data.get("file_path")
                    # ê²½ë¡œ í™•ì¸ ë””ë²„ê·¸ ì œê±°
                    
                    # Windows ê²½ë¡œ êµ¬ë¶„ì ì •ê·œí™”
                    if file_path:
                        file_path = file_path.replace('\\', '/')
                        # ê²½ë¡œ ì •ê·œí™” ë””ë²„ê·¸ ì œê±°
                    
                    if file_path and os.path.exists(file_path):
                        pass
                    else:
                        # ì‹¤ì œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ ê¸°ë¡
                        # ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë¡í•˜ê³  ê±´ë„ˆë›°ê¸°
                        orphaned_metadata.append(file_id)
                        continue
                    try:
                        # upload_time ì²˜ë¦¬ - ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
                        upload_time_raw = file_data.get("upload_time")
                        upload_time = datetime.now()  # ê¸°ë³¸ê°’ ì„¤ì •
                        
                        if isinstance(upload_time_raw, str):
                            try:
                                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                                if upload_time_raw.endswith('Z'):
                                    upload_time = datetime.fromisoformat(upload_time_raw.replace('Z', '+00:00'))
                                elif 'T' in upload_time_raw:
                                    upload_time = datetime.fromisoformat(upload_time_raw)
                                else:
                                    # "2025-08-05 19:56:50.113296" í˜•ì‹ ì²˜ë¦¬
                                    upload_time = datetime.strptime(upload_time_raw, "%Y-%m-%d %H:%M:%S.%f")
                            except ValueError as e:
                                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                                upload_time = datetime.now()
                        elif isinstance(upload_time_raw, datetime):
                            upload_time = upload_time_raw
                        else:
                            # ê¸°ë³¸ê°’ ì‚¬ìš©
                            pass
                        
                        # ì•ˆì „í•œ ë°ì´í„° íƒ€ì… ë³€í™˜
                        try:
                            file_size = int(file_data.get("file_size", file_data.get("size", 0)))
                        except (ValueError, TypeError):
                            file_size = 0
                        
                        try:
                            vectorized = bool(file_data.get("vectorized", False))
                        except (ValueError, TypeError):
                            vectorized = False
                        
                        # FileInfo ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë°ì´í„° ì •ë¦¬
                        file_info_data = {
                            "file_id": str(file_id),
                            "filename": str(file_data.get("filename", "")),
                            "status": str(file_data.get("status", "unknown")),
                            "file_size": file_size,
                            "category_id": file_data.get("category_id"),
                            "category_name": file_data.get("category_name"),
                            "upload_time": upload_time,
                            "vectorized": vectorized,
                            "vectorization_status": file_data.get("vectorization_status"),
                            "error_message": file_data.get("error_message")
                        }
                        
                        # ë²¡í„°í™” ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ë§Œ ë¡œê·¸ ì¶œë ¥
                        if file_data.get('vectorized') != vectorized:
                            print(f"ğŸ”„ ë²¡í„°í™” ìƒíƒœ ë³€ê²½ - {file_data.get('filename', 'Unknown')}: {file_data.get('vectorized')} â†’ {vectorized}")
                        
                        # ë””ë²„ê·¸: ë²¡í„°í™” ìƒíƒœ ì •ë³´ ì¶œë ¥ (í•„ìš”ì‹œ í™œì„±í™”)
                        # print(f"ğŸ” íŒŒì¼ {file_data.get('filename', 'Unknown')}: vectorized={vectorized} (raw: {file_data.get('vectorized')}), status={file_data.get('status')}, vectorization_status={file_data.get('vectorization_status')}")
                        
                        # ìƒì„± ì‹œë„ ë¡œê·¸ ì œê±°
                        
                        try:
                            file_info = FileInfo(**file_info_data)
                            files.append(file_info)
                            # ì„±ê³µ ë¡œê·¸ ì œê±°
                        except Exception as e:
                            # ì‹¤íŒ¨ ì‹œë§Œ ê°„ì†Œ ë©”ì‹œì§€
                            print(f"FileInfo ìƒì„± ì‹¤íŒ¨ - íŒŒì¼ ID: {file_id}, ì˜¤ë¥˜: {str(e)}")
                            continue
                        
                    except Exception as e:
                        print(f"íŒŒì¼ ì •ë³´ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ (íŒŒì¼ ID: {file_id}): {str(e)}")
                        import traceback
                        traceback.print_exc()
                        continue
                        
                except Exception as file_error:
                    print(f"ê°œë³„ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (íŒŒì¼ ID: {file_id}): {str(file_error)}")
                    continue
            
            # ê³ ì•„ ë©”íƒ€ë°ì´í„° ì •ë¦¬ (ì„ íƒì‚¬í•­)
            if orphaned_metadata:
                print(f"ë°œê²¬ëœ ê³ ì•„ ë©”íƒ€ë°ì´í„° {len(orphaned_metadata)}ê°œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
                for file_id in orphaned_metadata:
                    del self.files_metadata[file_id]
                self._save_files_metadata()
            
            # ì—…ë¡œë“œ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
            files.sort(key=lambda x: x.upload_time, reverse=True)
            
            # ì™„ë£Œ ë¡œê·¸ ì œê±°
            return files
            
        except Exception as e:
            print(f"list_filesì—ì„œ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            raise
    
    async def get_files_by_categories(self, category_ids: List[str] = None, categories: List[str] = None) -> List[FileInfo]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ë“¤ì˜ íŒŒì¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            files = []
            for file_data in self.files_metadata.values():
                # ì‚­ì œëœ íŒŒì¼ ì œì™¸
                if file_data.get("status") == "deleted":
                    continue
                    
                file_category_id = file_data.get("category_id")
                file_category_name = file_data.get("category_name")
                
                # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¨¼ì €
                file_path = file_data.get("file_path")
                # Windows ê²½ë¡œ êµ¬ë¶„ì ì •ê·œí™”
                if file_path:
                    file_path = file_path.replace('\\', '/')
                if not (file_path and os.path.exists(file_path)):
                    continue  # ì‹¤ì œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                
                # upload_time ì²˜ë¦¬
                upload_time_raw = file_data.get("upload_time")
                if isinstance(upload_time_raw, str):
                    try:
                        if upload_time_raw.endswith('Z'):
                            upload_time = datetime.fromisoformat(upload_time_raw.replace('Z', '+00:00'))
                        elif 'T' in upload_time_raw:
                            upload_time = datetime.fromisoformat(upload_time_raw)
                        else:
                            upload_time = datetime.strptime(upload_time_raw, "%Y-%m-%d %H:%M:%S.%f")
                    except ValueError:
                        upload_time = datetime.now()
                elif isinstance(upload_time_raw, datetime):
                    upload_time = upload_time_raw
                else:
                    upload_time = datetime.now()
                
                # FileInfo ë°ì´í„° ì¤€ë¹„
                file_info_data = {
                    "file_id": file_data.get("file_id", ""),
                    "filename": file_data.get("filename", ""),
                    "status": file_data.get("status", "unknown"),
                    "file_size": int(file_data.get("file_size", file_data.get("size", 0))),
                    "category_id": file_data.get("category_id"),
                    "category_name": file_data.get("category_name"),
                    "upload_time": upload_time,
                    "vectorized": bool(file_data.get("vectorized", False))
                }
                
                # ì¹´í…Œê³ ë¦¬ IDë¡œ í•„í„°ë§
                if category_ids and file_category_id in category_ids:
                    try:
                        files.append(FileInfo(**file_info_data))
                    except Exception as e:
                        print(f"FileInfo ìƒì„± ì‹¤íŒ¨ (ì¹´í…Œê³ ë¦¬ ID): {e}")
                    continue
                
                # ì¹´í…Œê³ ë¦¬ ì´ë¦„ìœ¼ë¡œ í•„í„°ë§
                if categories and file_category_name in categories:
                    try:
                        files.append(FileInfo(**file_info_data))
                    except Exception as e:
                        print(f"FileInfo ìƒì„± ì‹¤íŒ¨ (ì¹´í…Œê³ ë¦¬ ì´ë¦„): {e}")
                    continue
            
            # ì—…ë¡œë“œ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
            files.sort(key=lambda x: x.upload_time, reverse=True)
            return files
            
        except Exception as e:
            print(f"ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def delete_file(self, file_id: str) -> bool:
        """íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ ì •ë³´ ì¡°íšŒ
            file_data = self.files_metadata.get(file_id)
            if not file_data:
                print(f"íŒŒì¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return False
            
            deletion_errors = []
            
            # ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                file_path = file_data.get("file_path")
                if file_path and os.path.exists(file_path):
                    os.remove(file_path)
                    print(f"ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
                elif file_path:
                    print(f"ë¬¼ë¦¬ì  íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                else:
                    print(f"íŒŒì¼ ê²½ë¡œ ì •ë³´ê°€ ì—†ìŒ: {file_id}")
            except Exception as e:
                error_msg = f"ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}"
                print(error_msg)
                deletion_errors.append(error_msg)
            
            # ë²¡í„° ë°ì´í„° íŒŒì¼ ì‚­ì œ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                vector_file_path = os.path.join(
                    settings.DATA_DIR, 
                    f"vectors_{file_id}.json"
                )
                if os.path.exists(vector_file_path):
                    os.remove(vector_file_path)
                    print(f"ë²¡í„° ë°ì´í„° íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {vector_file_path}")
                else:
                    print(f"ë²¡í„° ë°ì´í„° íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {vector_file_path}")
            except Exception as e:
                error_msg = f"ë²¡í„° ë°ì´í„° íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}"
                print(error_msg)
                deletion_errors.append(error_msg)
            
            # ë²¡í„° ì„œë¹„ìŠ¤ì—ì„œ ë²¡í„° ë°ì´í„° ì‚­ì œ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                from .vector_service import VectorService
                vector_service = VectorService()
                await vector_service.delete_document_vectors(file_id)
                print(f"ChromaDB ë²¡í„° ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {file_id}")
            except Exception as e:
                error_msg = f"ChromaDB ë²¡í„° ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {str(e)}"
                print(error_msg)
                deletion_errors.append(error_msg)
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒì¼ì„ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ë§ˆí‚¹ (ì™„ì „ ì‚­ì œ ëŒ€ì‹ )
            try:
                self.files_metadata[file_id]["status"] = "deleted"
                self.files_metadata[file_id]["deleted_at"] = datetime.now()
                self.files_metadata[file_id]["deletion_errors"] = deletion_errors if deletion_errors else None
                self._save_files_metadata()
                print(f"íŒŒì¼ì„ ì‚­ì œë¨ìœ¼ë¡œ ë§ˆí‚¹ ì™„ë£Œ: {file_id}")
            except Exception as e:
                print(f"ë©”íƒ€ë°ì´í„° ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
                return False
            
            # ì‚­ì œ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸í•˜ì§€ë§Œ, ë©”íƒ€ë°ì´í„°ëŠ” ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            if deletion_errors:
                print(f"íŒŒì¼ ì‚­ì œ ê³¼ì •ì—ì„œ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒí–ˆì§€ë§Œ ë©”íƒ€ë°ì´í„°ëŠ” ì‚­ì œë¨: {deletion_errors}")
            
            return True
            
        except Exception as e:
            print(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    async def generate_missing_hashes(self) -> Dict[str, Any]:
        """ê¸°ì¡´ íŒŒì¼ë“¤ì˜ ëˆ„ë½ëœ í•´ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            import hashlib
            updated_files = []
            error_files = []
            
            for file_id, file_data in self.files_metadata.items():
                # í•´ì‹œê°€ ì—†ê³  ì‚­ì œë˜ì§€ ì•Šì€ íŒŒì¼ë“¤
                if (file_data.get("file_hash") is None and 
                    file_data.get("status") != "deleted"):
                    
                    file_path = file_data.get("file_path")
                    if file_path and os.path.exists(file_path):
                        try:
                            # íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ í•´ì‹œ ìƒì„±
                            with open(file_path, 'rb') as f:
                                content = f.read()
                                file_hash = hashlib.md5(content).hexdigest()
                            
                            # í•´ì‹œ ì •ë³´ ì¶”ê°€
                            file_data["file_hash"] = file_hash
                            updated_files.append({
                                "file_id": file_id,
                                "filename": file_data.get("filename"),
                                "hash": file_hash[:8]
                            })
                            
                        except Exception as e:
                            error_files.append({
                                "file_id": file_id,
                                "filename": file_data.get("filename"),
                                "error": str(e)
                            })
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            if updated_files:
                self._save_files_metadata()
                print(f"âœ… {len(updated_files)}ê°œ íŒŒì¼ì˜ í•´ì‹œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            return {
                "updated_count": len(updated_files),
                "error_count": len(error_files),
                "updated_files": updated_files,
                "error_files": error_files
            }
            
        except Exception as e:
            print(f"í•´ì‹œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    async def extract_text_from_pdf(self, file_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            from pypdf import PdfReader
            
            text = ""
            with open(file_path, 'rb') as file:
                pdf_reader = PdfReader(file)
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text.strip():
                            text += f"[í˜ì´ì§€ {page_num + 1}]\n{page_text}\n\n"
                    except Exception as e:
                        print(f"í˜ì´ì§€ {page_num + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                        continue
            
            return text.strip()
            
        except Exception as e:
            print(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return ""

    async def extract_text_from_office(self, file_path: str) -> str:
        """Office íŒŒì¼(DOC, PPT, XLS)ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            file_extension = os.path.splitext(file_path)[1].lower()
            text = ""
            
            if file_extension in ['.doc', '.docx']:
                # Word ë¬¸ì„œ ì²˜ë¦¬
                try:
                    from docx import Document
                    if file_extension == '.docx':
                        doc = Document(file_path)
                        for paragraph in doc.paragraphs:
                            if paragraph.text.strip():
                                text += paragraph.text + "\n"
                    else:
                        # .doc íŒŒì¼ì€ python-docxë¡œ ì§ì ‘ ì²˜ë¦¬ ë¶ˆê°€, ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
                        text = f"âš ï¸ .doc íŒŒì¼ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .docx íŒŒì¼ë¡œ ë³€í™˜ í›„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                except ImportError:
                    text = f"âš ï¸ Word íŒŒì¼ ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (python-docx)"
                except Exception as e:
                    text = f"âš ï¸ Word íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
                    
            elif file_extension in ['.ppt', '.pptx']:
                # PowerPoint íŒŒì¼ ì²˜ë¦¬
                try:
                    from pptx import Presentation
                    if file_extension == '.pptx':
                        prs = Presentation(file_path)
                        for slide_num, slide in enumerate(prs.slides):
                            text += f"[ìŠ¬ë¼ì´ë“œ {slide_num + 1}]\n"
                            for shape in slide.shapes:
                                if hasattr(shape, 'text') and shape.text.strip():
                                    text += shape.text + "\n"
                            text += "\n"
                    else:
                        # .ppt íŒŒì¼ì€ python-pptxë¡œ ì§ì ‘ ì²˜ë¦¬ ë¶ˆê°€
                        text = f"âš ï¸ .ppt íŒŒì¼ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .pptx íŒŒì¼ë¡œ ë³€í™˜ í›„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                except ImportError:
                    text = f"âš ï¸ PowerPoint íŒŒì¼ ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (python-pptx)"
                except Exception as e:
                    text = f"âš ï¸ PowerPoint íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
                    
            elif file_extension in ['.xls', '.xlsx']:
                # Excel íŒŒì¼ ì²˜ë¦¬
                try:
                    import openpyxl
                    if file_extension == '.xlsx':
                        wb = openpyxl.load_workbook(file_path, data_only=True)
                        for sheet_name in wb.sheetnames:
                            text += f"[ì‹œíŠ¸: {sheet_name}]\n"
                            sheet = wb[sheet_name]
                            for row in sheet.iter_rows(values_only=True):
                                row_text = []
                                for cell_value in row:
                                    if cell_value is not None:
                                        row_text.append(str(cell_value))
                                if row_text:
                                    text += " | ".join(row_text) + "\n"
                            text += "\n"
                    else:
                        # .xls íŒŒì¼ì€ xlrd ë“±ì´ í•„ìš”í•˜ì§€ë§Œ ë³µì¡í•˜ë¯€ë¡œ ê²½ê³  ë©”ì‹œì§€
                        text = f"âš ï¸ .xls íŒŒì¼ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .xlsx íŒŒì¼ë¡œ ë³€í™˜ í›„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                except ImportError:
                    text = f"âš ï¸ Excel íŒŒì¼ ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (openpyxl)"
                except Exception as e:
                    text = f"âš ï¸ Excel íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
            
            return text.strip() if text else "âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"Office íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def extract_text_from_file(self, file_path: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²•ì„ ì„ íƒí•©ë‹ˆë‹¤."""
        try:
            file_extension = os.path.splitext(file_path)[1].lower()
            
            if file_extension == '.pdf':
                return await self.extract_text_from_pdf(file_path)
            elif file_extension in ['.doc', '.docx', '.ppt', '.pptx', '.xls', '.xlsx']:
                return await self.extract_text_from_office(file_path)
            else:
                return f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}"
                
        except Exception as e:
            print(f"íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end - overlap
            
            if start >= len(text):
                break
        
        return chunks

    async def update_file_vectorization_status(self, file_id: str, vectorized: bool = True, error_message: str = None, vectorized_at: str = None) -> bool:
        """íŒŒì¼ì˜ ë²¡í„°í™” ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            if file_id not in self.files_metadata:
                print(f"íŒŒì¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return False
            
            # í˜„ì¬ ì‹œê°„
            if vectorized_at is None:
                vectorized_at = datetime.now().isoformat()
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            self.files_metadata[file_id].update({
                "vectorized": vectorized,
                "vectorized_at": vectorized_at,
                "status": "vectorized" if vectorized else "vectorization_failed"
            })
            
            # ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            if error_message:
                self.files_metadata[file_id]["error_message"] = error_message
                self.files_metadata[file_id]["vectorization_status"] = "failed"
            else:
                # ì„±ê³µí•œ ê²½ìš° ì˜¤ë¥˜ ì •ë³´ ì œê±°
                self.files_metadata[file_id].pop("error_message", None)
                self.files_metadata[file_id]["vectorization_status"] = "completed" if vectorized else "failed"
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ì— ì €ì¥
            self._save_files_metadata()
            
            print(f"íŒŒì¼ ë²¡í„°í™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {file_id} -> vectorized={vectorized}")
            return True
            
        except Exception as e:
            print(f"íŒŒì¼ ë²¡í„°í™” ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    async def get_file_path(self, file_id: str) -> Optional[str]:
        """íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            if file_id not in self.files_metadata:
                return None
            
            file_info = self.files_metadata[file_id]
            file_path = file_info.get("file_path")
            
            if file_path and os.path.exists(file_path):
                return file_path
            
            return None
        except Exception as e:
            print(f"íŒŒì¼ ê²½ë¡œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    async def cleanup_orphaned_metadata(self) -> int:
        """ê³ ì•„ ë©”íƒ€ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. (ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ë©”íƒ€ë°ì´í„° ì œê±°)"""
        try:
            orphaned_count = 0
            orphaned_ids = []
            
            for file_id, file_data in self.files_metadata.items():
                file_path = file_data.get("file_path")
                if not (file_path and os.path.exists(file_path)):
                    orphaned_ids.append(file_id)
                    print(f"ê³ ì•„ ë©”íƒ€ë°ì´í„° ë°œê²¬: {file_data.get('filename')} ({file_path})")
            
            # ê³ ì•„ ë©”íƒ€ë°ì´í„° ì œê±°
            for file_id in orphaned_ids:
                del self.files_metadata[file_id]
                orphaned_count += 1
            
            if orphaned_count > 0:
                self._save_files_metadata()
                print(f"ì´ {orphaned_count}ê°œì˜ ê³ ì•„ ë©”íƒ€ë°ì´í„°ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
            
            return orphaned_count
            
        except Exception as e:
            print(f"ê³ ì•„ ë©”íƒ€ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 0

    async def sync_files_with_storage(self) -> dict:
        """ìŠ¤í† ë¦¬ì§€ì™€ ë©”íƒ€ë°ì´í„° ë™ê¸°í™” ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            # ë©”íƒ€ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°
            orphaned_metadata = []
            # íŒŒì¼ì€ ìˆì§€ë§Œ ë©”íƒ€ë°ì´í„°ì— ì—†ëŠ” ê²½ìš°
            orphaned_files = []
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            for file_id, file_data in self.files_metadata.items():
                file_path = file_data.get("file_path")
                if not (file_path and os.path.exists(file_path)):
                    orphaned_metadata.append({
                        "file_id": file_id,
                        "filename": file_data.get("filename"),
                        "file_path": file_path
                    })
            
            # ì‹¤ì œ íŒŒì¼ í™•ì¸
            if os.path.exists(self.upload_dir):
                for filename in os.listdir(self.upload_dir):
                    file_path = os.path.join(self.upload_dir, filename)
                    if os.path.isfile(file_path):
                        # ì´ íŒŒì¼ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                        found_metadata = False
                        for file_data in self.files_metadata.values():
                            if file_data.get("file_path") == file_path:
                                found_metadata = True
                                break
                        
                        if not found_metadata:
                            orphaned_files.append({
                                "filename": filename,
                                "file_path": file_path,
                                "size": os.path.getsize(file_path)
                            })
            
            return {
                "orphaned_metadata": orphaned_metadata,
                "orphaned_files": orphaned_files,
                "orphaned_metadata_count": len(orphaned_metadata),
                "orphaned_files_count": len(orphaned_files)
            }
            
        except Exception as e:
            print(f"íŒŒì¼ ë™ê¸°í™” í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "orphaned_metadata": [],
                "orphaned_files": [],
                "orphaned_metadata_count": 0,
                "orphaned_files_count": 0,
                "error": str(e)
            }

    async def retry_vectorization(self, file_id: str) -> bool:
        """íŒŒì¼ì˜ ë²¡í„°í™”ë¥¼ ì¬ì‹œë„í•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ ì •ë³´ í™•ì¸
            file_info = await self.get_file_info(file_id)
            if not file_info:
                print(f"íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
                return False
            
            print(f"=== ë²¡í„°í™” ì¬ì‹œë„ ì‹œì‘: {file_id} ({file_info.filename}) ===")
            
            # íŒŒì¼ ìƒíƒœë¥¼ pending_vectorizationìœ¼ë¡œ ì¬ì„¤ì •
            if file_id in self.files_metadata:
                self.files_metadata[file_id]["status"] = "pending_vectorization"
                self.files_metadata[file_id]["vectorized"] = False
                # ì´ì „ ì˜¤ë¥˜ ì •ë³´ ì œê±°
                if "error" in self.files_metadata[file_id]:
                    del self.files_metadata[file_id]["error"]
                self._save_files_metadata()
                print(f"íŒŒì¼ ìƒíƒœë¥¼ pending_vectorizationìœ¼ë¡œ ì¬ì„¤ì •: {file_id}")
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë²¡í„°í™” ì¬ì‹œì‘
            import asyncio
            asyncio.create_task(self._start_vectorization(file_id))
            
            print(f"ë²¡í„°í™” ì¬ì‹œë„ ì‘ì—… ì‹œì‘: {file_id}")
            return True
            
        except Exception as e:
            print(f"ë²¡í„°í™” ì¬ì‹œë„ ì¤‘ ì˜¤ë¥˜: {file_id}, {str(e)}")
            return False 

    async def set_search_flow(self, flow_id: str) -> bool:
        """ê²€ìƒ‰ Flow ì„¤ì •"""
        try:
            from .langflow_service import LangflowService
            langflow_service = LangflowService()
            return await langflow_service.set_search_flow(flow_id)
        except Exception as e:
            print(f"ê²€ìƒ‰ Flow ì„¤ì • ì‹¤íŒ¨: {str(e)}")
            return False

    async def delete_flow(self, flow_id: str) -> bool:
        """Flow ì‚­ì œ"""
        try:
            from .langflow_service import LangflowService
            langflow_service = LangflowService()
            return await langflow_service.delete_flow(flow_id)
        except Exception as e:
            print(f"Flow ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            return False 

    async def sync_vectorization_status(self) -> dict:
        """ë²¡í„°í™” ìƒíƒœë¥¼ ì‹¤ì œ ChromaDB ë°ì´í„°ì™€ ë™ê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            print("=== ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™” ì‹œì‘ ===")
            
            # VectorService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            from .vector_service import VectorService
            vector_service = VectorService()
            
            # ChromaDB ìƒíƒœ í™•ì¸
            chroma_status = vector_service.get_chromadb_status()
            actual_vector_count = chroma_status.get("collection_count", 0)
            
            print(f"ì‹¤ì œ ChromaDB ì´ ë²¡í„° ê°œìˆ˜: {actual_vector_count}")
            
            # íŒŒì¼ë³„ ë²¡í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            sync_results = {
                "total_files": len(self.files_metadata),
                "files_with_vectors": 0,
                "files_without_vectors": 0,
                "status_corrected": 0,
                "details": []
            }
            
            for file_id, file_data in self.files_metadata.items():
                filename = file_data.get("filename", "Unknown")
                current_status = file_data.get("status", "unknown")
                current_vectorized = file_data.get("vectorized", False)
                
                # ChromaDBì—ì„œ í•´ë‹¹ íŒŒì¼ì˜ ë²¡í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                try:
                    file_vectors = await vector_service.get_document_chunks(file_id)
                    has_vectors = len(file_vectors) > 0
                    
                    # ìƒíƒœ ë¶ˆì¼ì¹˜ í™•ì¸
                    status_mismatch = False
                    if has_vectors and not current_vectorized:
                        # ë²¡í„°ëŠ” ìˆì§€ë§Œ ë©”íƒ€ë°ì´í„°ì— vectorized=False
                        status_mismatch = True
                        self.files_metadata[file_id]["vectorized"] = True
                        self.files_metadata[file_id]["status"] = "vectorized"
                        sync_results["status_corrected"] += 1
                        print(f"âœ… ìˆ˜ì •: {filename} - ë²¡í„° ì¡´ì¬í•˜ì§€ë§Œ ë©”íƒ€ë°ì´í„°ì— vectorized=False")
                        
                    elif not has_vectors and current_vectorized:
                        # ë²¡í„°ëŠ” ì—†ì§€ë§Œ ë©”íƒ€ë°ì´í„°ì— vectorized=True
                        status_mismatch = True
                        self.files_metadata[file_id]["vectorized"] = False
                        self.files_metadata[file_id]["status"] = "vectorization_failed"
                        sync_results["status_corrected"] += 1
                        print(f"âŒ ìˆ˜ì •: {filename} - ë²¡í„° ì—†ì§€ë§Œ ë©”íƒ€ë°ì´í„°ì— vectorized=True")
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    if has_vectors:
                        sync_results["files_with_vectors"] += 1
                    else:
                        sync_results["files_without_vectors"] += 1
                    
                    sync_results["details"].append({
                        "file_id": file_id,
                        "filename": filename,
                        "has_vectors": has_vectors,
                        "metadata_vectorized": current_vectorized,
                        "status_mismatch": status_mismatch,
                        "vector_count": len(file_vectors)
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ë²¡í„° í™•ì¸ ì‹¤íŒ¨: {filename} - {str(e)}")
                    sync_results["details"].append({
                        "file_id": file_id,
                        "filename": filename,
                        "has_vectors": False,
                        "metadata_vectorized": current_vectorized,
                        "status_mismatch": False,
                        "error": str(e)
                    })
                    sync_results["files_without_vectors"] += 1
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            if sync_results["status_corrected"] > 0:
                self._save_files_metadata()
                print(f"âœ… {sync_results['status_corrected']}ê°œ íŒŒì¼ì˜ ìƒíƒœë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.")
            
            print(f"=== ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™” ì™„ë£Œ ===")
            print(f"ì´ íŒŒì¼: {sync_results['total_files']}")
            print(f"ë²¡í„° ìˆëŠ” íŒŒì¼: {sync_results['files_with_vectors']}")
            print(f"ë²¡í„° ì—†ëŠ” íŒŒì¼: {sync_results['files_without_vectors']}")
            print(f"ìƒíƒœ ìˆ˜ì •ëœ íŒŒì¼: {sync_results['status_corrected']}")
            
            return sync_results
            
        except Exception as e:
            print(f"ë²¡í„°í™” ìƒíƒœ ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return {
                "error": str(e),
                "total_files": 0,
                "files_with_vectors": 0,
                "files_without_vectors": 0,
                "status_corrected": 0,
                "details": []
            } 