import time
import os
import json
from typing import Dict, Any, List
from ..models.schemas import ChatRequest, ChatResponse
from ..core.config import settings
from .file_service import FileService
from .langflow_service import LangflowService
from .persona_service import PersonaService
from .system_settings_service import SystemSettingsService
import openai
from datetime import datetime

class ChatService:
    def __init__(self):
        self.openai_client = None
        self.file_service = FileService()
        self.langflow_service = LangflowService()
        self.persona_service = PersonaService()
        self.system_settings_service = SystemSettingsService()
        if settings.OPENAI_API_KEY:
            openai.api_key = settings.OPENAI_API_KEY
            self.openai_client = openai
    
    async def process_chat(self, request: ChatRequest) -> ChatResponse:
        """ì±„íŒ… ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        start_time = time.time()
        
        try:
            print(f"=== ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ ===")
            print(f"ì‚¬ìš©ì ID: {request.user_id}")
            print(f"ë©”ì‹œì§€: {request.message}")
            print(f"ì¹´í…Œê³ ë¦¬ IDs: {request.category_ids}")
            print(f"Flow ID: {request.flow_id}")
            print(f"í˜ë¥´ì†Œë‚˜ ID: {request.persona_id}")
            print(f"ì‹œìŠ¤í…œ ë©”ì‹œì§€: {request.system_message}")
            print(f"ì²¨ë¶€ëœ ì´ë¯¸ì§€ ìˆ˜: {len(request.images) if request.images else 0}")
            
            # ìµœì¢… ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„± (í˜ë¥´ì†Œë‚˜ + ì„¤ì • ì¡°í•©)
            final_system_message = await self._build_system_message(request.system_message, request.persona_id)
            print(f"ìµœì¢… ì‹œìŠ¤í…œ ë©”ì‹œì§€: {final_system_message}")
            
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            if request.user_id:
                await self._save_chat_message(
                    user_id=request.user_id,
                    message=request.message,
                    role="user",
                    category_ids=request.category_ids
                )
            
            # ê¸°ë³¸ ê²€ìƒ‰ Flow ID í™•ì¸
            search_flow_id = request.flow_id or await self._get_default_search_flow()
            
            if search_flow_id:
                print(f"LangFlow ê²€ìƒ‰ Flow ì‚¬ìš©: {search_flow_id}")
                # LangFlow ê²€ìƒ‰ í”Œë¡œìš° ì‹¤í–‰
                langflow_result = await self.langflow_service.search_with_flow(
                    request.message,
                    search_flow_id,
                    request.category_ids,
                    top_k=request.top_k  # ìš”ì²­ì—ì„œ top_k ì„¤ì • ì‚¬ìš©
                )
                
                print(f"LangFlow ê²°ê³¼: {langflow_result}")
                
                # LangFlow ê²°ê³¼ì—ì„œ ì‘ë‹µê³¼ ì†ŒìŠ¤ ì¶”ì¶œ
                if langflow_result.get("status") == "success":
                    # ì§ì ‘ ChromaDB ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
                    search_results = langflow_result.get("results", [])
                    print(f"ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë°œê²¬")
                    
                    if search_results:
                        # ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡° í™•ì¸ì„ ìœ„í•œ ë””ë²„ê·¸
                        print(f"ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°: {search_results[0] if search_results else 'None'}")
                        
                        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        relevant_documents = []
                        for i, result in enumerate(search_results):
                            metadata = result.get("metadata", {})
                            filename = metadata.get("filename", "") or metadata.get("file_name", "") or metadata.get("source", "")
                            
                            doc = {
                                "file_id": metadata.get("file_id", ""),
                                "filename": filename,
                                "category_id": metadata.get("category_id", ""),
                                "category_name": metadata.get("category_name", ""),
                                "content": result.get("text", "") or result.get("content", ""),
                                "score": result.get("score", 1.0),
                                "distance": result.get("distance", 1.0)
                            }
                            relevant_documents.append(doc)
                            
                            print(f"ë³€í™˜ëœ ë¬¸ì„œ {i+1}: file_id={doc['file_id']}, filename='{doc['filename']}', score={doc['score']:.3f}, distance={doc['distance']:.3f}")
                        
                        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ê°€ ë¨¼ì €)
                        relevant_documents.sort(key=lambda x: x['score'], reverse=True)
                        print(f"ì ìˆ˜ìˆœ ì •ë ¬ í›„ ì²« 3ê°œ ë¬¸ì„œ:")
                        for i, doc in enumerate(relevant_documents[:3]):
                            print(f"  {i+1}ìœ„: {doc['filename']} (ì ìˆ˜: {doc['score']:.3f})")
                        
                        # LangFlowë¥¼ í†µí•´ ì‘ë‹µ ìƒì„± (Flow ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©)
                        if request.images and len(request.images) > 0:
                            # ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
                            print(f"ë©€í‹°ëª¨ë‹¬ ëª¨ë“œ: ì´ë¯¸ì§€ {len(request.images)}ê°œì™€ í…ìŠ¤íŠ¸ ì²˜ë¦¬")
                            response_text = await self.generate_multimodal_response_with_flow(
                                request.message, 
                                request.images,
                                relevant_documents, 
                                final_system_message,
                                search_flow_id
                            )
                        else:
                            # ê¸°ì¡´ í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬
                            response_text = await self.generate_response_with_flow(
                                request.message, 
                                relevant_documents, 
                                final_system_message,
                                search_flow_id
                            )
                    else:
                        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        response_text = "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        relevant_documents = []
                else:
                    print(f"LangFlow ì‹¤í–‰ ì‹¤íŒ¨: {langflow_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    # LangFlow ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                    relevant_documents = await self.search_documents(
                        request.message, 
                        request.category_ids,
                        request.categories
                    )
                    response_text = await self.generate_response_with_flow(
                        request.message, 
                        relevant_documents, 
                        final_system_message,
                        None  # fallbackì¼ ë•ŒëŠ” ê¸°ë³¸ flow ì‚¬ìš©
                    )
            else:
                print("ê²€ìƒ‰ Flowê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ê¸°ë³¸ ê²€ìƒ‰ (fallback)
                relevant_documents = await self.search_documents(
                    request.message, 
                    request.category_ids,
                    request.categories
                )
                response_text = await self.generate_response_with_flow(
                    request.message, 
                    relevant_documents, 
                    final_system_message,
                    None  # ê¸°ë³¸ flow ì‚¬ìš©
                )
            
            processing_time = time.time() - start_time
            print(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            # ì†ŒìŠ¤ ë¬¸ì„œ: íŒŒì¼ ë‹¨ìœ„ë¡œ ì¤‘ë³µ ì œê±°(ë™ì¼ ë¬¸ì„œëŠ” 1ê°œë§Œ)
            print(f"ì¤‘ë³µ ì œê±° ì „ relevant_documents: {[doc.get('filename', 'NO_NAME') for doc in relevant_documents]}")
            sources_for_response = self._unique_sources(relevant_documents)
            print(f"ì¤‘ë³µ ì œê±° í›„ sources_for_response: {[src.get('filename', 'NO_NAME') for src in sources_for_response]}")

            # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥
            if request.user_id:
                await self._save_chat_message(
                    user_id=request.user_id,
                    message=response_text,
                    role="assistant",
                    category_ids=request.category_ids,
                    sources=sources_for_response
                )
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ë‹¨ìˆœí™”)
            confidence = 0.7  # ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì • (ì„ì‹œ)
            if relevant_documents:
                print(f"ë¬¸ì„œ {len(relevant_documents)}ê°œ ë°œê²¬, ì‹ ë¢°ë„: {confidence}")
            else:
                confidence = 0.3
                print(f"ë¬¸ì„œ ì—†ìŒ, ì‹ ë¢°ë„: {confidence}")
            
            print(f"ê³„ì‚°ëœ ì‹ ë¢°ë„: {confidence:.3f} (ì›ë³¸ ë¬¸ì„œ {len(relevant_documents)}ê°œ, ìœ ë‹ˆí¬ ì†ŒìŠ¤ {len(sources_for_response)}ê°œ)")
            
            return ChatResponse(
                response=response_text,
                sources=sources_for_response,
                confidence=confidence,
                processing_time=processing_time,
                categories=request.categories,
                flow_id=search_flow_id,
                user_id=request.user_id
            )
            
        except Exception as e:
            print(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            processing_time = time.time() - start_time
            return ChatResponse(
                response=f"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sources=[],
                confidence=0.0,
                processing_time=processing_time,
                categories=request.categories or [],
                flow_id=request.flow_id,
                user_id=request.user_id
            )
    
    async def execute_langflow_flow(self, flow_id: str, message: str, context: List[Dict[str, Any]] = None) -> str:
        """íŠ¹ì • Langflow Flowë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            # TODO: ì‹¤ì œ Langflow Flow ì‹¤í–‰ ë¡œì§ êµ¬í˜„
            # 1. Flow IDë¡œ Flow JSON ë¡œë“œ
            # 2. ì»¨í…ìŠ¤íŠ¸ì™€ ë©”ì‹œì§€ë¥¼ Flowì— ì „ë‹¬
            # 3. Flow ì‹¤í–‰ ê²°ê³¼ ë°˜í™˜
            
            # ì„ì‹œ êµ¬í˜„
            context_text = ""
            if context:
                context_text = "\n".join([doc.get("content", "") for doc in context])
            
            return f"Flow {flow_id} ì‹¤í–‰ ê²°ê³¼: {message}\n\nì°¸ê³  ë¬¸ì„œ:\n{context_text}"
            
        except Exception as e:
            return f"Flow ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def search_documents(self, query: str, category_ids: List[str] = None, categories: List[str] = None) -> List[Dict[str, Any]]:
        """ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ í•„í„°ë§
            if category_ids or categories:
                files = await self.file_service.get_files_by_categories(category_ids, categories)
            else:
                files = await self.file_service.list_files()
            
            # ë²¡í„°í™”ëœ ë¬¸ì„œì—ì„œ ê²€ìƒ‰
            documents = []
            for file_info in files[:5]:  # ìµœëŒ€ 5ê°œ íŒŒì¼
                if file_info.vectorized:
                    # ë²¡í„° ë°ì´í„° ë¡œë“œ
                    vector_content = await self._load_vector_data(file_info.file_id)
                    if vector_content:
                        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°)
                        relevant_chunks = await self._search_chunks(query, vector_content.get("chunks", []))
                        
                        for chunk in relevant_chunks[:3]:  # íŒŒì¼ë‹¹ ìµœëŒ€ 3ê°œ ì²­í¬
                            documents.append({
                                "file_id": file_info.file_id,
                                "filename": file_info.filename,
                                "category_id": file_info.category_id,
                                "category_name": file_info.category_name,
                                "content": chunk,
                                "score": 0.8
                            })
                else:
                    # ë²¡í„°í™”ë˜ì§€ ì•Šì€ íŒŒì¼ì€ ë©”íƒ€ë°ì´í„°ë§Œ ì œê³µ
                    documents.append({
                        "file_id": file_info.file_id,
                        "filename": file_info.filename,
                        "category_id": file_info.category_id,
                        "category_name": file_info.category_name,
                        "content": f"{file_info.filename} (ì•„ì§ ë²¡í„°í™”ë˜ì§€ ì•ŠìŒ)",
                        "score": 0.3
                    })
            
            return documents
            
        except Exception as e:
            print(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def generate_response_with_flow(self, query: str, context: List[Dict[str, Any]], system_message: str = None, flow_id: str = None) -> str:
        """LangFlowë¥¼ í†µí•´ ë™ì ìœ¼ë¡œ ì„ íƒëœ LLM ëª¨ë¸ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
            context_sections = []
            sources_info = []
            
            print(f"=== LangFlow ê¸°ë°˜ LLM ì‘ë‹µ ìƒì„± ì‹œì‘ ===")
            print(f"ì‚¬ìš© Flow ID: {flow_id}")
            print(f"ì „ë‹¬ë°›ì€ ë¬¸ì„œ ìˆ˜: {len(context)}")
            
            for i, doc in enumerate(context, 1):
                source_name = doc.get("filename", f"ë¬¸ì„œ{i}")
                content = doc.get("content", "")
                
                # ê° ë¬¸ì„œë¥¼ ëª…í™•íˆ êµ¬ë¶„
                context_sections.append(f"=== ë¬¸ì„œ {i}: {source_name} ===\n{content}\n")
                sources_info.append(f"[{i}] {source_name}")
                
                print(f"ë¬¸ì„œ {i}: {source_name} (ê¸¸ì´: {len(content)} ê¸€ì)")
            
            # ëª¨ë“  ë¬¸ì„œ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            context_text = "\n".join(context_sections)
            sources_text = "\n".join(sources_info) if sources_info else "ì°¸ê³  ë¬¸ì„œ ì—†ìŒ"
            
            print(f"=== ìµœì¢… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ ===")
            print(f"ì†ŒìŠ¤ ì •ë³´: {sources_text}")
            print(f"ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_text)} ê¸€ì")
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸ ë° ì¶•ì†Œ
            if len(context_text) > 8000:  # 8000ì ì œí•œ
                print(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ {len(context_text)}ì, ì¶•ì†Œ í•„ìš”")
                # ê° ë¬¸ì„œë¥¼ 500ìë¡œ ì œí•œ
                shortened_sections = []
                for i, doc in enumerate(context, 1):
                    source_name = doc.get("filename", f"ë¬¸ì„œ{i}")
                    content = doc.get("content", "")[:500] + ("..." if len(doc.get("content", "")) > 500 else "")
                    shortened_sections.append(f"=== ë¬¸ì„œ {i}: {source_name} ===\n{content}\n")
                context_text = "\n".join(shortened_sections)
                print(f"ì¶•ì†Œ í›„ ê¸¸ì´: {len(context_text)}ì")

            # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ì¶œì²˜ë¥¼ [1], [2] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{sources_text}

ë‚´ìš©:
{context_text}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

            # LangFlowë¥¼ í†µí•´ LLM ì‹¤í–‰
            flow_id_to_use = flow_id or await self._get_default_search_flow()
            if flow_id_to_use:
                print(f"LangFlow ì‹¤í–‰: {flow_id_to_use}")
                langflow_result = await self.langflow_service.execute_flow_with_llm(
                    flow_id_to_use,
                    prompt,
                    system_message
                )
                
                if langflow_result.get("status") == "success":
                    response_text = langflow_result.get("response", "LangFlowì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    print(f"LangFlow ì‘ë‹µ ì„±ê³µ: {len(response_text)} ê¸€ì")
                    return response_text
                else:
                    print(f"LangFlow ì‹¤í–‰ ì‹¤íŒ¨: {langflow_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    # Fallback to original method
                    return await self.generate_response_fallback(query, context, system_message)
            else:
                print("Flow IDê°€ ì—†ìŠµë‹ˆë‹¤. Fallback ì‚¬ìš©")
                return await self.generate_response_fallback(query, context, system_message)
                
        except Exception as e:
            print(f"LangFlow ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            # Fallback to original method
            return await self.generate_response_fallback(query, context, system_message)

    async def generate_response_fallback(self, query: str, context: List[Dict[str, Any]], system_message: str = None) -> str:
        """Fallback: ê¸°ì¡´ OpenAI ì§ì ‘ í˜¸ì¶œ ë°©ì‹"""
        print("=== Fallback: OpenAI ì§ì ‘ í˜¸ì¶œ ì‚¬ìš© ===")
        return await self.generate_response(query, context, system_message)

    async def generate_response(self, query: str, context: List[Dict[str, Any]], system_message: str = None) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.openai_client:
            return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
            context_sections = []
            sources_info = []
            
            print(f"=== LLM ì „ë‹¬ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì‹œì‘ ===")
            print(f"ì „ë‹¬ë°›ì€ ë¬¸ì„œ ìˆ˜: {len(context)}")
            
            for i, doc in enumerate(context, 1):
                source_name = doc.get("filename", f"ë¬¸ì„œ{i}")
                content = doc.get("content", "")
                
                # ê° ë¬¸ì„œë¥¼ ëª…í™•íˆ êµ¬ë¶„
                context_sections.append(f"=== ë¬¸ì„œ {i}: {source_name} ===\n{content}\n")
                sources_info.append(f"[{i}] {source_name}")
                
                print(f"ë¬¸ì„œ {i}: {source_name} (ê¸¸ì´: {len(content)} ê¸€ì)")
            
            # ëª¨ë“  ë¬¸ì„œ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            context_text = "\n".join(context_sections)
            sources_text = "\n".join(sources_info) if sources_info else "ì°¸ê³  ë¬¸ì„œ ì—†ìŒ"
            
            print(f"=== ìµœì¢… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ ===")
            print(f"ì†ŒìŠ¤ ì •ë³´: {sources_text}")
            print(f"ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_text)} ê¸€ì")
            
            prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ëª¨ë‘ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€í•  ë•Œ ê´€ë ¨ëœ ì¶œì²˜ë¥¼ [1], [2] í˜•íƒœë¡œ ì¸ë¼ì¸ì— í‘œì‹œí•´ì£¼ì„¸ìš”.

ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œ ëª©ë¡:
{sources_text}

ëª¨ë“  ë¬¸ì„œ ë‚´ìš©:
{context_text}

ì§ˆë¬¸: {query}

ë‹µë³€ ê·œì¹™:
1. ëª¨ë“  ê´€ë ¨ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ë‹µë³€ ë‚´ìš©ì— ê´€ë ¨ëœ ì¶œì²˜ë¥¼ [1], [2] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”  
3. ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì–»ì€ ì •ë³´ëŠ” ëª¨ë‘ í™œìš©í•˜ì„¸ìš”"""
            
            # LangFlowë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„±
            if flow_id:
                print(f"LangFlow ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œì‘: {flow_id}")
                try:
                    langflow_result = await self.langflow_service.execute_multimodal_flow_with_llm(
                        flow_id, 
                        prompt, 
                        images,
                        system_message
                    )
                    
                    if langflow_result.get("status") == "success":
                        print(f"LangFlow ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì„±ê³µ")
                        return langflow_result.get("response", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        print(f"LangFlow ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤íŒ¨: {langflow_result.get('error')}")
                        # í´ë°±: OpenAI API ì§ì ‘ ì‚¬ìš©
                        
                except Exception as e:
                    print(f"LangFlow ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")
                    # í´ë°±: OpenAI API ì§ì ‘ ì‚¬ìš©
            
            # í´ë°± ë˜ëŠ” flow_idê°€ ì—†ëŠ” ê²½ìš°: OpenAI API ì§ì ‘ ì‚¬ìš© (í…ìŠ¤íŠ¸ ì „ìš©)
            print("í…ìŠ¤íŠ¸ ì „ìš© í´ë°± ì²˜ë¦¬")
            try:
                from openai import OpenAI
                client = OpenAI(api_key=settings.OPENAI_API_KEY)
                
                # ì „ë‹¬ë°›ì€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì‚¬ìš© (ì´ë¯¸ _build_system_messageì—ì„œ ì²˜ë¦¬ë¨)
                final_system_message = system_message
                
                print(f"ì‚¬ìš©ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€: {final_system_message}")
                
                # OpenAI API í˜¸ì¶œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                openai_start_time = time.time()
                print(f"OpenAI API í˜¸ì¶œ ì‹œì‘: gpt-3.5-turbo, max_tokens=1500")
                
                # ì´ë¯¸ì§€ê°€ ìˆë‹¤ëŠ” ê²ƒì„ í…ìŠ¤íŠ¸ì— ëª…ì‹œ
                image_note = f"\n\nì°¸ê³ : ì‚¬ìš©ìê°€ {len(images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í–ˆìœ¼ë‚˜, í˜„ì¬ í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œë¡œ ì²˜ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤."
                final_prompt = prompt + image_note
                
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",  # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ gpt-3.5-turbo ì‚¬ìš©
                    messages=[
                        {"role": "system", "content": final_system_message},
                        {"role": "user", "content": final_prompt}
                    ],
                    max_tokens=1500,
                    temperature=0.7
                )
                
                openai_time = time.time() - openai_start_time
                print(f"OpenAI API í˜¸ì¶œ ì™„ë£Œ: {openai_time:.2f}ì´ˆ")
                
                return response.choices[0].message.content
                
            except Exception as openai_error:
                print(f"OpenAI API í´ë°± ì‹¤íŒ¨: {str(openai_error)}")
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {str(openai_error)}"
            
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _load_vector_data(self, file_id: str) -> Dict[str, Any]:
        """ë²¡í„° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            vector_file_path = os.path.join(
                settings.DATA_DIR, 
                f"vectors_{file_id}.json"
            )
            
            if os.path.exists(vector_file_path):
                with open(vector_file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return None
            
        except Exception as e:
            print(f"ë²¡í„° ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _search_chunks(self, query: str, chunks: List[str]) -> List[str]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì²­í¬ ê²€ìƒ‰ (ì‹¤ì œë¡œëŠ” ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°)"""
        try:
            query_lower = query.lower()
            relevant_chunks = []
            
            for chunk in chunks:
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
                if any(keyword in chunk.lower() for keyword in query_lower.split()):
                    relevant_chunks.append(chunk)
            
            # ìµœëŒ€ 5ê°œ ì²­í¬ ë°˜í™˜
            return relevant_chunks[:5]
            
        except Exception as e:
            print(f"ì²­í¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def _get_default_search_flow(self) -> str:
        """ê¸°ë³¸ ê²€ìƒ‰ Flow IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ ê²€ìƒ‰ Flow ID ì½ê¸°
            config_file = os.path.join(settings.BASE_DIR, "langflow", "config.json")
            
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                return config_data.get("default_search_flow_id")
            
            return None
            
        except Exception as e:
            print(f"ê¸°ë³¸ ê²€ìƒ‰ Flow ID ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _extract_sources_from_langflow_result(self, langflow_result: Dict[str, Any], category_ids: List[str] = None) -> List[Dict[str, Any]]:
        """LangFlow ê²°ê³¼ì—ì„œ ì†ŒìŠ¤ ë¬¸ì„œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            sources = []
            
            # LangFlow ê²°ê³¼ì—ì„œ ì‚¬ìš©ëœ íŒŒì¼ ì •ë³´ ì¶”ì¶œ (êµ¬í˜„ í•„ìš”)
            # í˜„ì¬ëŠ” ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜
            if category_ids:
                files = await self.file_service.get_files_by_categories(category_ids, None)
                for file_info in files[:3]:  # ìµœëŒ€ 3ê°œ íŒŒì¼
                    if file_info.vectorized:
                        sources.append({
                            "file_id": file_info.file_id,
                            "filename": file_info.filename,
                            "category_id": file_info.category_id,
                            "category_name": file_info.category_name,
                            "content": f"ğŸ“„ {file_info.filename}ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
                            "score": 0.9
                        })
            
            return sources
            
        except Exception as e:
            print(f"ì†ŒìŠ¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return [] 

    def _unique_sources(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """íŒŒì¼ëª… ê¸°ì¤€ ì¤‘ë³µ ì œê±°: ë™ì¼ íŒŒì¼ëª…ì€ 1ê°œë§Œ ë°˜í™˜"""
        if not documents:
            print("=== ì¤‘ë³µ ì œê±°: ì…ë ¥ ë¬¸ì„œ ì—†ìŒ ===")
            return []
            
        print(f"=== ì¤‘ë³µ ì œê±° ì‹œì‘ ===")
        print(f"ì…ë ¥ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        
        # ì…ë ¥ ë¬¸ì„œë“¤ì˜ íŒŒì¼ëª… í™•ì¸
        filenames = [doc.get("filename", "EMPTY") for doc in documents]
        print(f"ëª¨ë“  íŒŒì¼ëª…: {filenames}")
        
        # ê°•ë ¥í•œ ì¤‘ë³µ ì œê±°: filenameì„ ì •ê·œí™”í•˜ê³  ì¤‘ë³µ ì œê±°
        seen_filenames = set()
        result = []
        
        for i, doc in enumerate(documents):
            filename = doc.get("filename", "").strip()
            if not filename:
                print(f"ë¬¸ì„œ {i}: filenameì´ ë¹„ì–´ìˆìŒ, ê±´ë„ˆëœ€")
                continue
                
            # íŒŒì¼ëª… ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
            normalized_filename = filename.lower().strip()
            
            if normalized_filename not in seen_filenames:
                seen_filenames.add(normalized_filename)
                result.append({
                    "file_id": doc.get("file_id", ""),
                    "filename": filename,  # ì›ë³¸ íŒŒì¼ëª… ìœ ì§€
                    "category_id": doc.get("category_id", ""),
                    "category_name": doc.get("category_name", ""),
                })
                print(f"ë¬¸ì„œ {i}: filename='{filename}' ì¶”ê°€ë¨ (ì •ê·œí™”: {normalized_filename})")
            else:
                print(f"ë¬¸ì„œ {i}: filename='{filename}' ì¤‘ë³µ (ì •ê·œí™”: {normalized_filename}), ê±´ë„ˆëœ€")
        
        print(f"ìµœì¢… ìœ ë‹ˆí¬ ì†ŒìŠ¤ ìˆ˜: {len(result)}")
        print(f"ìœ ë‹ˆí¬ ì†ŒìŠ¤ë“¤: {[r['filename'] for r in result]}")
        print(f"=== ì¤‘ë³µ ì œê±° ì™„ë£Œ ===")
        return result

    async def get_chat_history(self, user_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ìë³„ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            history_file = os.path.join(
                settings.DATA_DIR, 
                'chat_history.json'
            )
            
            if not os.path.exists(history_file):
                return []
            
            with open(history_file, 'r', encoding='utf-8') as f:
                all_history = json.load(f)
            
            # ì‚¬ìš©ìë³„ íˆìŠ¤í† ë¦¬ í•„í„°ë§
            user_history = all_history.get(user_id, [])
            
            # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  limitë§Œí¼ ë°˜í™˜
            sorted_history = sorted(user_history, key=lambda x: x.get('timestamp', ''), reverse=True)
            return sorted_history[:limit]
            
        except Exception as e:
            print(f"ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return []

    async def save_chat_history(self, user_id: str, user_message: dict, assistant_message: dict) -> bool:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            history_file = os.path.join(
                settings.DATA_DIR, 
                'chat_history.json'
            )
            
            # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ
            all_history = {}
            if os.path.exists(history_file):
                with open(history_file, 'r', encoding='utf-8') as f:
                    all_history = json.load(f)
            
            # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            if user_id not in all_history:
                all_history[user_id] = []
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            user_msg = {
                "id": user_message.get("id", str(int(time.time() * 1000))),
                "message": user_message.get("content", ""),
                "role": "user",
                "timestamp": user_message.get("timestamp", datetime.now().isoformat()),
                "category_ids": user_message.get("categories", []),
                "sources": user_message.get("sources", [])
            }
            
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
            assistant_msg = {
                "id": assistant_message.get("id", str(int(time.time() * 1000) + 1)),
                "message": assistant_message.get("content", ""),
                "role": "assistant",
                "timestamp": assistant_message.get("timestamp", datetime.now().isoformat()),
                "category_ids": assistant_message.get("categories", []),
                "sources": assistant_message.get("sources", []),
                "source_details": assistant_message.get("sourceDetails", []),
                "processing_time": assistant_message.get("processingTime"),
                "confidence": assistant_message.get("confidence")
            }
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            all_history[user_id].extend([user_msg, assistant_msg])
            
            # ìµœëŒ€ 100ê°œ ë©”ì‹œì§€ë¡œ ì œí•œ (50ê°œ ëŒ€í™”)
            if len(all_history[user_id]) > 100:
                all_history[user_id] = all_history[user_id][-100:]
            
            # íŒŒì¼ì— ì €ì¥
            os.makedirs(os.path.dirname(history_file), exist_ok=True)
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(all_history, f, ensure_ascii=False, indent=2)
            
            print(f"ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ: {user_id}")
            return True
            
        except Exception as e:
            print(f"ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return False

    async def _save_chat_message(
        self, 
        user_id: str, 
        message: str, 
        role: str, 
        category_ids: List[str] = None,
        sources: List[Dict[str, Any]] = None
    ):
        """ì±„íŒ… ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            history_file = os.path.join(
                settings.DATA_DIR, 
                'chat_history.json'
            )
            
            # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ
            all_history = {}
            if os.path.exists(history_file):
                with open(history_file, 'r', encoding='utf-8') as f:
                    all_history = json.load(f)
            
            # ì‚¬ìš©ìë³„ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            if user_id not in all_history:
                all_history[user_id] = []
            
            # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
            chat_message = {
                "id": f"{user_id}_{int(time.time() * 1000)}",
                "user_id": user_id,
                "message": message,
                "role": role,
                "timestamp": datetime.now().isoformat(),
                "category_ids": category_ids or [],
                "sources": sources or []
            }
            
            all_history[user_id].append(chat_message)
            
            # ìµœëŒ€ 1000ê°œ ë©”ì‹œì§€ ìœ ì§€
            if len(all_history[user_id]) > 1000:
                all_history[user_id] = all_history[user_id][-1000:]
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(all_history, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"ì±„íŒ… ë©”ì‹œì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    async def _build_system_message(self, custom_message: str = None, persona_id: str = None) -> str:
        """ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤: ê¸°ë³¸/ì‚¬ìš©ì ì§€ì • ë©”ì‹œì§€ + (ì„ íƒ) í˜ë¥´ì†Œë‚˜ ë©”ì‹œì§€ ê²°í•©."""
        try:
            # ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ì„¤ì • or ì‚¬ìš©ì ì§€ì •)
            if custom_message:
                print("ì‚¬ìš©ì ì§€ì • ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì‚¬ìš©")
                base_message = custom_message
            else:
                base_message = await self.system_settings_service.get_default_system_message()
                print("ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì‚¬ìš©")

            # ì‚¬ìš©í•  í˜ë¥´ì†Œë‚˜ ê²°ì •: ìš”ì²­ > ì‹œìŠ¤í…œ ê¸°ë³¸
            chosen_persona_id = persona_id or await self.system_settings_service.get_default_persona_id()

            persona_text = None
            if chosen_persona_id:
                persona = await self.persona_service.get_persona(chosen_persona_id)
                if persona and persona.system_message:
                    print(f"í˜ë¥´ì†Œë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨: {persona.name}")
                    persona_text = persona.system_message
                else:
                    print(f"í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—†ìŒ: {chosen_persona_id}")

            if persona_text:
                return f"{base_message}\n\n{persona_text}"
            return base_message

        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ìµœì¢… í´ë°±: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’
            return "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ë‹µë³€í•  ë•Œ ê´€ë ¨ëœ ì¶œì²˜ë¥¼ [1], [2] í˜•íƒœë¡œ ì¸ë¼ì¸ì— í‘œì‹œí•´ì£¼ì„¸ìš”."
    
    async def generate_multimodal_response_with_flow(self, query: str, images: List[str], context: List[Dict[str, Any]], system_message: str = None, flow_id: str = None) -> str:
        """ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„±: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            print(f"=== ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„± ì‹œì‘ ===")
            print(f"í…ìŠ¤íŠ¸: {query[:100]}...")
            print(f"ì´ë¯¸ì§€ ìˆ˜: {len(images)}")
            print(f"ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìˆ˜: {len(context)}")
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì™€ ë™ì¼)
            context_sections = []
            sources_info = []
            
            for i, doc in enumerate(context, 1):
                source_name = doc.get("filename", f"ë¬¸ì„œ{i}")
                content = doc.get("content", "")
                
                context_sections.append(f"=== ë¬¸ì„œ {i}: {source_name} ===\n{content}\n")
                sources_info.append(f"[{i}] {source_name}")
            
            context_text = "\n".join(context_sections)
            sources_text = "\n".join(sources_info) if sources_info else "ì°¸ê³  ë¬¸ì„œ ì—†ìŒ"
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë©€í‹°ëª¨ë‹¬ì—ì„œëŠ” ë” ì§§ê²Œ)
            if len(context_text) > 5000:  # ì´ë¯¸ì§€ ë•Œë¬¸ì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ë” ì¤„ì„
                print(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ {len(context_text)}ì, ì¶•ì†Œ í•„ìš”")
                shortened_sections = []
                for i, doc in enumerate(context, 1):
                    source_name = doc.get("filename", f"ë¬¸ì„œ{i}")
                    content = doc.get("content", "")[:300] + ("..." if len(doc.get("content", "")) > 300 else "")
                    shortened_sections.append(f"=== ë¬¸ì„œ {i}: {source_name} ===\n{content}\n")
                context_text = "\n".join(shortened_sections)
                print(f"ì¶•ì†Œ í›„ ê¸¸ì´: {len(context_text)}ì")

            # ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì´ë¯¸ì§€ ë¶„ì„ + ë¬¸ì„œ ì°¸ê³ )
            prompt = f"""ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì°¸ê³  ë¬¸ì„œë¥¼ í•¨ê»˜ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{sources_text}

ë¬¸ì„œ ë‚´ìš©:
{context_text}

ì§ˆë¬¸: {query}

ë‹µë³€ ì‹œ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
1. ì´ë¯¸ì§€ì—ì„œ ê´€ì°°ë˜ëŠ” ë‚´ìš© ë¶„ì„
2. ì°¸ê³  ë¬¸ì„œì˜ ê´€ë ¨ ì •ë³´ í™œìš©
3. ì´ë¯¸ì§€ì™€ ë¬¸ì„œ ì •ë³´ë¥¼ ì¢…í•©í•œ ìµœì¢… ë‹µë³€
4. ì¶œì²˜ëŠ” [1], [2] í˜•íƒœë¡œ í‘œì‹œ

ë‹µë³€:"""

            # LangFlowë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ LLM ì‹¤í–‰
            flow_id_to_use = flow_id or await self._get_default_search_flow()
            if flow_id_to_use:
                print(f"ë©€í‹°ëª¨ë‹¬ LangFlow ì‹¤í–‰: {flow_id_to_use}")
                langflow_result = await self.langflow_service.execute_multimodal_flow_with_llm(
                    flow_id_to_use,
                    prompt,
                    images,
                    system_message
                )
                
                if langflow_result.get("status") == "success":
                    response_text = langflow_result.get("response", "ë©€í‹°ëª¨ë‹¬ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    print(f"ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ì„±ê³µ: {len(response_text)} ê¸€ì")
                    return response_text
                else:
                    print(f"ë©€í‹°ëª¨ë‹¬ ì‹¤í–‰ ì‹¤íŒ¨: {langflow_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    # Fallback: ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                    return await self.generate_response_with_flow(query, context, system_message, flow_id)
            else:
                print("Flow IDê°€ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì „ìš© Fallback ì‚¬ìš©")
                return await self.generate_response_with_flow(query, context, system_message, None)
                
        except Exception as e:
            print(f"ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            # Fallback: í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬
            return await self.generate_response_with_flow(query, context, system_message, flow_id)